---
layout: post
title: "POST TITLE"
date: 2020-12-xx 10:30:00 -0700
tags: CATEGORY-1 CATEGORY-2
comments: true
image:
summary:
---
Consequentialism can be a way of describing the payoffs, or can be a way of constructing the payoffs. Or similarly with ea.

These days perhaps I prefer it as a description of them, not as a method. Often you shouldn't calculate a thing out, but you should be aiming at the best consequences.

If the two diverge, you should do the thing that you think will get the best consequences, not the thing that you calculate will.

A downside of this is that it allows more bias to slip in. (But you know that, and others do, and can choose the amount of explicit reasoning that seems best consequentially, given that.) An upside is that it reduces the need for justifications that spread lies to other ears, maybe. You can just say, 'i don't know why, but I think it will go better if we don't kill these people even though it looks like we consequentially should' and you don't have to then really pin this to some philosophically watertight theory of action in society. You can just present it as what it is: a brute guess about what will happen.
