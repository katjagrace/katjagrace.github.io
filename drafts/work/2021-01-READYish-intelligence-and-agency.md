---
layout: post
title: "Intelligence and agency"
date: 2021-01-xx 10:30:00 -0700
tags: CATEGORY-1 CATEGORY-2
comments: true
image:
summary:
---
There is a concern about super-intelligent agents being created, and sending humanity extinct. In particular, the agency of the created entity is important: the stories about how agents destroy the world are much clearer and more common than the stories about how non-agents destroy the world.

There seems to be a common thought that advanced AI is likely to be in the form of agents because sufficiently optimal cognition begets agency. Like, the reason that you can currently make toast without doing great damage is just that your toaster is stupid. If it becomes super-intelligent, then it isn't currently clear how you could ask it for toast without having it somehow interfere in everything else in the universe. (If this is an out of date account of the concern, I'm curious to hear.)

A couple of questions I have about this, that hopefully someone has answered elsewhere and could direct me to:
1. Why must the smartest thing, in the relevant sense, must be an agent?
2. Even if it is clear that in the limit intelligent things are agentic, do we know anything about how large a gap there is between where we or our machines are, and the level of intelligence where you can't avoid being an agent?

(I think there are other reasons to expect some or much of advanced AI to be in the form of agents, to be clear. For instance, agents can do stuff that non-agents can't. But I'm interested in sorting out the different arguments.)

*Thanks to Joe Carlsmith for discussion.*

maybe read these then reconsider:
https://www.gwern.net/Tool-AI
https://arbital.com/p/optimized_agent_appears_coherent/

Joe thinks is not what people think these days and/or eliezer one might answer 1
