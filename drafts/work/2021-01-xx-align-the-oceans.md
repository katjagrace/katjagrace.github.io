---
layout: post
title: "Do we have to align the ocean?"
date: 2021-01-xx 10:30:00 -0700
tags: CATEGORY-1 CATEGORY-2
comments: true
image:
summary:
---
[what does paul say about tools needing aligning? make it clearer why you would worry about the non aligned things earlier, probably people don't say things are going to hell if we don't align everything]
A worry that I have about this 'align the AI' plan&mdash;in the basic schema of everything being ultimately terrible if not aligned&mdash;is that I imagine we are building technology that you kind of attach to any agent that you are making, or run any agent through, and then it is good. But I doubt that 'agents' are super well defined, for instance, there are outcome-directed processes that are not in the minds of specific humans, such as 'the marketplace'.

Do we have to align the marketplace? Do we have to align the street, or Twitter, or every incarnation of [the collective action problem](https://en.wikipedia.org/wiki/Collective_action_problem)? These things are not very agentic, but are they zero agentic? If you think things are going to go to hell eventually unless the agents are aligned, it seems concerning.

Also, things that seem pretty agent-like exist at different levels of abstraction. There's you, there's your company, your partnership, your country, there's the majority of your brain but not the bits responsible for whatever happens when you see your boyfriend chatting with that girl, which you don't endorse or identify with. Do all of those have to be aligned?  

You might point out that we are only concerned about alignment because the 'agents' in question are going to be super powerful. But 'super' doesn't seem to be well defined, and it seems quite plausible that many non-agentic processes will also be super-powered in all this, relative to how they are now. Not just super-AI-tools, but the pressures applied by the street, say, might be much stronger if billions of agents per second are trying to use the street, instead one per ten seconds.

I guess it seems like the world is really full of roiling sea of atoms and shit, and if you were doomed if you didn't do a certain maneuver to every 'agent' in it, you'd have problems.

I guess the answer is that it is actually not that bad as long as you get the most powerful ones, and yes, that might involve aligning the marketplace or something, if there don't end up being a small number of AI agents that can overwhelm it.
