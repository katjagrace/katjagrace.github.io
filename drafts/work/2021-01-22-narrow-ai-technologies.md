---
layout: post
title: "POST TITLE"
date: 2021-01-xx 10:30:00 -0700
tags: CATEGORY-1 CATEGORY-2
comments: true
image:
summary:
---
1. there are and will be many narrow AI applications possible, before we get to really advanced AI

2. there is much less effort for making them than available ones to be made at each point in time (so society has a lot of choice in which order to make them)

3. narrow AI applications widely vary in their value, from hugely destructive to hugely positive, including for x-risk. i.e. there are probably some that help with x-risk, and some that worsen it.

4. the order in which these are created might have a large effect on society's functioning or on x-risk (even if ultimately they are all created). e.g. if detection and demonstration of falsehoods technology were ahead of pro-falsehood technology, social epistemology might look much better.

5. his is a very tractable thing for some people to influence: in particular, those choosing what to build, and perhaps more so, those choosing what to fund.

6. thus very high upside work, if nobody is doing it: map out possible narrow technologies, and evaluate their consequences for long-term societal thriving. Note dependencies and ordering considerations. Estimate consequences of each early. Make map of these technologies and their expected value and dependencies. Report to funders.

Examples:
- Evaluate support for claims from online sources, on online forums
- Write literature reviews: speeds up science generally
- Detect agentic behavior beyond what is expected in choices of other systems
- Present counterarguments to claims about AI safety
- Intelligent surveillance, that interprets what it sees, and reports certain kinds of important upshots broadly (e.g. can report that a war or terror attack is being planned, but doesn't cause any of your personal discussion with boyfriend to be seen by any human)
- resolve philosophical problems or present argument for impossibility
- present compelling arguments for anything
- present one-sided true case, constructed from larger set of ambiguous information
- design objects
