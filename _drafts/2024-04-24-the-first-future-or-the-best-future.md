---
layout: post
title: "The first future or the best future"
date: 2024-04-24 23:22:00 -0700
tags: meteuphoric ai
comments: true
image: 
summary: if you are going to make the same choice a million times, you should probably experiment a bit. 
---

It seems to me worth [trying to slow down AI development](https://worldspiritsockpuppet.substack.com/p/lets-think-about-slowing-down-ai) to steer successfully around the shoals of extinction and out to utopia.

But I was thinking lately: even if I didn't think there was any chance of extinction risk, it might still be worth prioritizing a lot of care over moving at maximal speed. Because there are many different possible AI futures, and I think there's a good chance that the initial direction affects the long term path, and different long term paths go to different places. The systems we build now will shape the next systems, and so forth. If the first human-level-ish AI is brain emulations, I expect a quite different sequence of events to if it is GPT-ish.

People genuinely pushing for AI speed over care (rather than just feeling impotent) apparently think there is negligible risk of bad outcomes, but also they are asking to take the first future to which there is a path. Yet possible futures are a large space, and arguably we are in a rare plateau where we could climb very different hills, and get to much better futures. 
