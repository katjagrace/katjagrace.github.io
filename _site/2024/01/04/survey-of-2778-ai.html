<!DOCTYPE html>
<html lang="en"><head>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Benne&display=swap" rel="stylesheet">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Survey of 2,778 AI authors: six parts in pictures | world spirit sock puppet</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Survey of 2,778 AI authors: six parts in pictures" />
<meta name="author" content="Katja Grace" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Crossposted from AI Impacts blog The 2023 Expert Survey on Progress in AI is out, this time with 2778 participants from six top AI venues (up from about 700 and two in the 2022 ESPAI), making it probably the biggest ever survey of AI researchers. People answered in October, an eventful fourteen months after the 2022 survey, which had mostly identical questions for comparison. Here is the preprint. And here are six interesting bits in pictures (with figure numbers matching paper, for ease of learning more): 1. Expected time to human-level performance dropped 1-5 decades since the 2022 survey. As always, our questions about ‘high level machine intelligence’ (HLMI) and ‘full automation of labor’ (FAOL) got very different answers, and individuals disagreed a lot (shown as thin lines below), but the aggregate forecasts for both sets of questions dropped sharply. For context, between 2016 and 2022 surveys, the forecast for HLMI had only shifted about a year. (Fig 3) (Fig 4)" />
<meta property="og:description" content="Crossposted from AI Impacts blog The 2023 Expert Survey on Progress in AI is out, this time with 2778 participants from six top AI venues (up from about 700 and two in the 2022 ESPAI), making it probably the biggest ever survey of AI researchers. People answered in October, an eventful fourteen months after the 2022 survey, which had mostly identical questions for comparison. Here is the preprint. And here are six interesting bits in pictures (with figure numbers matching paper, for ease of learning more): 1. Expected time to human-level performance dropped 1-5 decades since the 2022 survey. As always, our questions about ‘high level machine intelligence’ (HLMI) and ‘full automation of labor’ (FAOL) got very different answers, and individuals disagreed a lot (shown as thin lines below), but the aggregate forecasts for both sets of questions dropped sharply. For context, between 2016 and 2022 surveys, the forecast for HLMI had only shifted about a year. (Fig 3) (Fig 4)" />
<link rel="canonical" href="http://localhost:4000/2024/01/04/survey-of-2778-ai.html" />
<meta property="og:url" content="http://localhost:4000/2024/01/04/survey-of-2778-ai.html" />
<meta property="og:site_name" content="world spirit sock puppet" />
<meta property="og:image" content="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6uJBqeG5ywE6Wcdqw/zusla2aogk561nuoejku" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-01-04T17:00:01-08:00" />
<script type="application/ld+json">
{"@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2024/01/04/survey-of-2778-ai.html"},"description":"Crossposted from AI Impacts blog The 2023 Expert Survey on Progress in AI is out, this time with 2778 participants from six top AI venues (up from about 700 and two in the 2022 ESPAI), making it probably the biggest ever survey of AI researchers. People answered in October, an eventful fourteen months after the 2022 survey, which had mostly identical questions for comparison. Here is the preprint. And here are six interesting bits in pictures (with figure numbers matching paper, for ease of learning more): 1. Expected time to human-level performance dropped 1-5 decades since the 2022 survey. As always, our questions about ‘high level machine intelligence’ (HLMI) and ‘full automation of labor’ (FAOL) got very different answers, and individuals disagreed a lot (shown as thin lines below), but the aggregate forecasts for both sets of questions dropped sharply. For context, between 2016 and 2022 surveys, the forecast for HLMI had only shifted about a year. (Fig 3) (Fig 4)","author":{"@type":"Person","name":"Katja Grace"},"image":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6uJBqeG5ywE6Wcdqw/zusla2aogk561nuoejku","headline":"Survey of 2,778 AI authors: six parts in pictures","dateModified":"2024-01-04T17:00:01-08:00","url":"http://localhost:4000/2024/01/04/survey-of-2778-ai.html","datePublished":"2024-01-04T17:00:01-08:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="world spirit sock puppet" /><!-- Twitter cards -->
  <meta name="twitter:site"    content="@KatjaGrace">
  <meta name="twitter:creator" content="@">
  <meta name="twitter:title"   content="Survey of 2,778 AI authors: six parts in pictures">

  
  <meta name="twitter:description" content="Results from the 2023 Expert Survey on Progress in AI">
  

  
  <meta name="twitter:card"  content="summary_large_image">
  <meta name="twitter:image" content="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6uJBqeG5ywE6Wcdqw/zusla2aogk561nuoejku">
  
  <!-- end of Twitter cards -->
</head>
<body><div class="FeaturedImgBanner"  >
  <header class="site-header" role="banner">
    <!-- Include your post title, byline, date, and other info inside the header here. -->

    <div class="wrapper"><a class="site-title" rel="author" href="/">world spirit sock puppet</a><nav class="site-nav">
          <input type="checkbox" id="nav-trigger" class="nav-trigger" />
          <label for="nav-trigger">
            <span class="menu-icon">
              <svg viewBox="0 0 18 15" width="18px" height="15px">
                <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
              </svg>
            </span>
          </label>
<br>
          <div class="trigger"><a class="page-link" href="/about/">About</a>
              <!-- <a class="page-link" href="/about/"><img src= height=20px alt=About></a> --><a class="page-link" href="/search/">Search</a>
              <!-- <a class="page-link" href="/search/"><img src= height=20px alt=Search></a> --><a class="page-link" href="/subscribe/">Subscribe</a>
              <!-- <a class="page-link" href="/subscribe/"><img src= height=20px alt=Subscribe></a> --></div>
        </nav></div>
  </header>
</div>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <br>
    <br>
    <h1 class="post-title p-name" itemprop="name headline">Survey of 2,778 AI authors: six parts in pictures</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2024-01-04T17:00:01-08:00" itemprop="datePublished">Jan 4, 2024
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>
<em>Crossposted from<a href="https://blog.aiimpacts.org/p/2023-ai-survey-of-2778-six-things"> AI Impacts blog</a></em>
</p>
<p>
The 2023 Expert Survey on Progress in AI is<a href="https://aiimpacts.org/wp-content/uploads/2023/04/Thousands_of_AI_authors_on_the_future_of_AI.pdf"> out</a>, this time with 2778 participants from six top AI venues (up from<a href="https://wiki.aiimpacts.org/ai_timelines/predictions_of_human-level_ai_timelines/ai_timeline_surveys/2022_expert_survey_on_progress_in_ai#population"> about 700</a> and two in the<a href="https://wiki.aiimpacts.org/ai_timelines/predictions_of_human-level_ai_timelines/ai_timeline_surveys/2022_expert_survey_on_progress_in_ai"> 2022 ESPAI</a>), making it probably the biggest ever survey of AI researchers.
</p>
<p>
People answered in October, an eventful fourteen months after the 2022 survey, which had mostly identical questions for comparison.
</p>
<p>
<a href="https://aiimpacts.org/wp-content/uploads/2023/04/Thousands_of_AI_authors_on_the_future_of_AI.pdf">Here</a> is the preprint. And here are six interesting bits in pictures (with figure numbers matching paper, for ease of learning more):
</p>
<p>
<strong>1. Expected time to human-level performance dropped 1-5 decades since the 2022 survey. </strong>As always, our questions about ‘high level machine intelligence’ (HLMI) and ‘full automation of labor’ (FAOL) got very different answers, and individuals disagreed a lot (shown as thin lines below), but the aggregate forecasts for both sets of questions dropped sharply. For context, between 2016 and 2022 surveys, the forecast for HLMI had only shifted about a year.
</p>
<p>

<img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6uJBqeG5ywE6Wcdqw/kvngwylqnpf0tvlf8g8a" width="" alt="Probability assigned to HLMI over time" title="image_tooltip" />
(Fig 3)

<img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6uJBqeG5ywE6Wcdqw/nllvn2ilyfuifmyoboa2" width="" alt="Probability assigned to FAOL over time" title="image_tooltip" />
(Fig 4)
</p>
<!--ex-->
<p>
 
</p>
<p>
<strong>2. Time to most narrow milestones decreased, some by a lot. </strong>AI researchers are expected to be professionally fully automatable a quarter of a century earlier than in 2022, and NYT bestselling fiction dropped by more than half to ~2030. Within five years, AI systems are forecast to be feasible that can fully make a payment processing site from scratch, or entirely generate a new song that sounds like it’s by e.g. Taylor Swift, or autonomously download and fine-tune a large language model.
</p>
<p>

<img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6uJBqeG5ywE6Wcdqw/lkogl5wintmggyw4upeg" width="" alt="Change in guesses about time to specific narrow capabilities" title="image_tooltip" />
(Fig 2)
</p>
<p>
 
</p>
<p>
<strong>3. Median respondents put 5% or more on advanced AI leading to human extinction or similar, and a third to a half of participants gave 10% or more. </strong>This was across four questions, one about overall value of the future and three more directly about extinction.
</p>
<p>

<img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6uJBqeG5ywE6Wcdqw/czh3xjxt7w1hwtojijeh" width="" alt="Around 40% of participants gave at least 10% chance to human extinction from AI" title="image_tooltip" />
(Fig 10)
</p>
<p>
 
</p>
<p>
<strong>4. Many participants found many scenarios worthy of substantial concern over the next 30 years.</strong> For every one of eleven scenarios and ‘other’ that we asked about, at least a third of participants considered it deserving of substantial or extreme concern.
</p>
<p>

<img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6uJBqeG5ywE6Wcdqw/pkrmpgh619mzaa703ncu" width="" alt="Level of concern warranted by different scenarios" title="image_tooltip" />
(Fig 9)
</p>
<p>
 
</p>
<p>
<strong>5. There are few confident optimists or pessimists about advanced AI: high hopes and dire concerns are usually found together.</strong> 68% of participants who thought HLMI was more likely to lead to good outcomes than bad, but nearly half of these people put at least 5% on extremely bad outcomes such as human extinction, and 59% of net pessimists gave 5% or more to extremely good outcomes.
</p>
<p>

<img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6uJBqeG5ywE6Wcdqw/zusla2aogk561nuoejku" width="" alt="800 responses to how likely the future being different levels of good is after HLMI" title="image_tooltip" />
(Fig 11: a random 800 responses as vertical bars, higher definition below)
</p>
<p>
 
</p>
<p>
<a href="https://blog.aiimpacts.org/api/v1/file/29c9bfb8-5d57-4b5f-9ffe-e50691268b4d.pdf">Download</a>
</p>
<p>
<strong>6. 70% of participants would like to see research aimed at minimizing risks of AI systems be prioritized more highly.</strong> This is much like 2022, and in both years a third of participants asked for “much more”—more than doubling since 2016.
</p>
<p>

<img src="https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/6uJBqeG5ywE6Wcdqw/zk5xgvtclrtpeuc8ymkh" width="" alt="how much should safety research be prioritized?" title="image_tooltip" />
(Fig 15)
</p>
<p>
 
</p>
<p>
If you enjoyed this,<a href="https://aiimpacts.org/wp-content/uploads/2023/04/Thousands_of_AI_authors_on_the_future_of_AI.pdf"> the paper</a> covers many other questions, as well as more details on the above. What makes AI progress go? Has it sped up? Would it be better if it were slower or faster? What will AI systems be like in 2043? Will we be able to know the reasons for its choices before then? Do people from academia and industry have different views? Are concerns about AI due to misunderstandings of AI research? Do people who completed undergraduate study in Asia put higher chances on extinction from AI than those who studied in America? Is the ‘alignment problem’ worth working on?
</p>

  </div><a class="u-url" href="/2024/01/04/survey-of-2778-ai.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>


  <div class="wrapper">
    <!-- <div>
      <h2 class="footer-heading"><a href="/list.html">Full archive</a></h2>
    </div> -->

    <!-- <div>
      <h2 class="footer-heading">Search</h2>
<script async src="https://cse.google.com/cse.js?cx=06d4880e018d74eb0">
</script>
<div class="gcse-search"></div>
</div> -->


    <br>

    <h2 class="footer-heading"><a href="/">world spirit sock puppet</a></h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <p>Inclusive writings of Katja Grace</p>
        <a href="/list.html">Full archive</a>
        <br>
        <ul class="contact-list">
          <li class="p-name">
            <!--Katja Grace-->
            </li><ul class="social-media-list"><li><a href="https://www.twitter.com/KatjaGrace"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">KatjaGrace</span></a></li></ul>
<li><a class="u-email" href="mailto:katjasolveig@gmail.com">katjasolveig@gmail.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2">
        <!--<ul class="social-media-list"><li><a href="https://www.twitter.com/KatjaGrace"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">KatjaGrace</span></a></li></ul>
-->
      </div>

      <div class="footer-col footer-col-3">
        <h4 class="footer-heading">Search</h4>
<script async src="https://cse.google.com/cse.js?cx=06d4880e018d74eb0">
</script>
<div class="gcse-search"></div>
</div>
    </div>

  </div>


</footer>
</body>

</html>
