<!DOCTYPE html>
<html lang="en"><head>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Benne&display=swap" rel="stylesheet">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Are we so good to simulate? | world spirit sock puppet</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Are we so good to simulate?" />
<meta name="author" content="Katja Grace" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="If you believe that,— a) a civilization like ours is likely to survive into technological incredibleness, and b) a technologically incredible civilization is very likely to create ‘ancestor simulations’, —then the Simulation Argument says you should expect that you are currently in such an ancestor simulation, rather than in the genuine historical civilization that later gives rise to an abundance of future people. Not officially included in the argument I think, but commonly believed: both a) and b) seem pretty likely, ergo we should conclude we are in a simulation. I don’t know about this. Here’s my counterargument: ‘Simulations’ here are people who are intentionally misled about their whereabouts in the universe. For the sake of argument, let’s use the term ‘simulation’ for all such people, including e.g. biological people who have been grown in Truman-show-esque situations. In the long run, the cost of running a simulation of a confused mind is probably similar to that of running a non-confused mind. Probably much, much less than 50% of the resources allocated to computing minds in the long run will be allocated to confused minds, because non-confused minds are generally more useful than confused minds. There are some uses for confused minds, but quite a lot of uses for non-confused minds. (This is debatable.) Of resources directed toward minds in the future, I’d guess less than a thousandth is directed toward confused minds. Thus on average, for a given apparent location in the universe, the majority of minds thinking they are in that location are correct. (I guess at at least a thousand to one.) For people in our situation to be majority simulations, this would have to be a vastly more simulated location than average, like &gt;1000x I agree there’s some merit to simulating ancestors, but 1000x more simulated than average is a lot - is it clear that we are that radically desirable a people to simulate? Perhaps, but also we haven’t thought much about the other people to simulate, or what will go in in the rest of the universe. Possibly we are radically over-salient to us. It’s true that we are a very few people in the history of what might be a very large set of people, at perhaps a causally relevant point. But is it clear that is a very, very strong reason to simulate some people in detail? It feels like it might be salient because it is what makes us stand out, and someone who has the most energy-efficient brain in the Milky Way would think that was the obviously especially strong reason to simulate a mind, etc." />
<meta property="og:description" content="If you believe that,— a) a civilization like ours is likely to survive into technological incredibleness, and b) a technologically incredible civilization is very likely to create ‘ancestor simulations’, —then the Simulation Argument says you should expect that you are currently in such an ancestor simulation, rather than in the genuine historical civilization that later gives rise to an abundance of future people. Not officially included in the argument I think, but commonly believed: both a) and b) seem pretty likely, ergo we should conclude we are in a simulation. I don’t know about this. Here’s my counterargument: ‘Simulations’ here are people who are intentionally misled about their whereabouts in the universe. For the sake of argument, let’s use the term ‘simulation’ for all such people, including e.g. biological people who have been grown in Truman-show-esque situations. In the long run, the cost of running a simulation of a confused mind is probably similar to that of running a non-confused mind. Probably much, much less than 50% of the resources allocated to computing minds in the long run will be allocated to confused minds, because non-confused minds are generally more useful than confused minds. There are some uses for confused minds, but quite a lot of uses for non-confused minds. (This is debatable.) Of resources directed toward minds in the future, I’d guess less than a thousandth is directed toward confused minds. Thus on average, for a given apparent location in the universe, the majority of minds thinking they are in that location are correct. (I guess at at least a thousand to one.) For people in our situation to be majority simulations, this would have to be a vastly more simulated location than average, like &gt;1000x I agree there’s some merit to simulating ancestors, but 1000x more simulated than average is a lot - is it clear that we are that radically desirable a people to simulate? Perhaps, but also we haven’t thought much about the other people to simulate, or what will go in in the rest of the universe. Possibly we are radically over-salient to us. It’s true that we are a very few people in the history of what might be a very large set of people, at perhaps a causally relevant point. But is it clear that is a very, very strong reason to simulate some people in detail? It feels like it might be salient because it is what makes us stand out, and someone who has the most energy-efficient brain in the Milky Way would think that was the obviously especially strong reason to simulate a mind, etc." />
<link rel="canonical" href="http://localhost:4000/2024/03/03/are-we-so-good-to-simulate.html" />
<meta property="og:url" content="http://localhost:4000/2024/03/03/are-we-so-good-to-simulate.html" />
<meta property="og:site_name" content="world spirit sock puppet" />
<meta property="og:image" content="https://hosting.photobucket.com/images/i/katjasgrace/katjagrace_people_living_in_a_simulation_gustav_klimt_fe27b7cd-8151-4ef1-9e6c-1de429a19249.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-03-03T19:01:00-08:00" />
<script type="application/ld+json">
{"@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2024/03/03/are-we-so-good-to-simulate.html"},"description":"If you believe that,— a) a civilization like ours is likely to survive into technological incredibleness, and b) a technologically incredible civilization is very likely to create ‘ancestor simulations’, —then the Simulation Argument says you should expect that you are currently in such an ancestor simulation, rather than in the genuine historical civilization that later gives rise to an abundance of future people. Not officially included in the argument I think, but commonly believed: both a) and b) seem pretty likely, ergo we should conclude we are in a simulation. I don’t know about this. Here’s my counterargument: ‘Simulations’ here are people who are intentionally misled about their whereabouts in the universe. For the sake of argument, let’s use the term ‘simulation’ for all such people, including e.g. biological people who have been grown in Truman-show-esque situations. In the long run, the cost of running a simulation of a confused mind is probably similar to that of running a non-confused mind. Probably much, much less than 50% of the resources allocated to computing minds in the long run will be allocated to confused minds, because non-confused minds are generally more useful than confused minds. There are some uses for confused minds, but quite a lot of uses for non-confused minds. (This is debatable.) Of resources directed toward minds in the future, I’d guess less than a thousandth is directed toward confused minds. Thus on average, for a given apparent location in the universe, the majority of minds thinking they are in that location are correct. (I guess at at least a thousand to one.) For people in our situation to be majority simulations, this would have to be a vastly more simulated location than average, like &gt;1000x I agree there’s some merit to simulating ancestors, but 1000x more simulated than average is a lot - is it clear that we are that radically desirable a people to simulate? Perhaps, but also we haven’t thought much about the other people to simulate, or what will go in in the rest of the universe. Possibly we are radically over-salient to us. It’s true that we are a very few people in the history of what might be a very large set of people, at perhaps a causally relevant point. But is it clear that is a very, very strong reason to simulate some people in detail? It feels like it might be salient because it is what makes us stand out, and someone who has the most energy-efficient brain in the Milky Way would think that was the obviously especially strong reason to simulate a mind, etc.","author":{"@type":"Person","name":"Katja Grace"},"image":"https://hosting.photobucket.com/images/i/katjasgrace/katjagrace_people_living_in_a_simulation_gustav_klimt_fe27b7cd-8151-4ef1-9e6c-1de429a19249.png","headline":"Are we so good to simulate?","dateModified":"2024-03-03T19:01:00-08:00","url":"http://localhost:4000/2024/03/03/are-we-so-good-to-simulate.html","datePublished":"2024-03-03T19:01:00-08:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="world spirit sock puppet" /><!-- Twitter cards -->
  <meta name="twitter:site"    content="@KatjaGrace">
  <meta name="twitter:creator" content="@">
  <meta name="twitter:title"   content="Are we so good to simulate?">

  
  <meta name="twitter:description" content="There might be a lot of other people">
  

  
  <meta name="twitter:card"  content="summary_large_image">
  <meta name="twitter:image" content="https://hosting.photobucket.com/images/i/katjasgrace/katjagrace_people_living_in_a_simulation_gustav_klimt_fe27b7cd-8151-4ef1-9e6c-1de429a19249.png">
  
  <!-- end of Twitter cards -->
</head>
<body><div class="FeaturedImgBanner"  >
  <header class="site-header" role="banner">
    <!-- Include your post title, byline, date, and other info inside the header here. -->

    <div class="wrapper"><a class="site-title" rel="author" href="/">world spirit sock puppet</a><nav class="site-nav">
          <input type="checkbox" id="nav-trigger" class="nav-trigger" />
          <label for="nav-trigger">
            <span class="menu-icon">
              <svg viewBox="0 0 18 15" width="18px" height="15px">
                <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
              </svg>
            </span>
          </label>
<br>
          <div class="trigger"><a class="page-link" href="/about/">About</a>
              <!-- <a class="page-link" href="/about/"><img src= height=20px alt=About></a> --><a class="page-link" href="/search/">Search</a>
              <!-- <a class="page-link" href="/search/"><img src= height=20px alt=Search></a> --><a class="page-link" href="/subscribe/">Subscribe</a>
              <!-- <a class="page-link" href="/subscribe/"><img src= height=20px alt=Subscribe></a> --></div>
        </nav></div>
  </header>
</div>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <br>
    <br>
    <h1 class="post-title p-name" itemprop="name headline">Are we so good to simulate?</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2024-03-03T19:01:00-08:00" itemprop="datePublished">Mar 3, 2024
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>If you believe that,—</p>

<p>a) a civilization like ours is likely to survive into technological incredibleness, and</p>

<p>b) a technologically incredible civilization is very likely to create ‘ancestor simulations’,</p>

<p>—then the Simulation Argument says you should expect that you are currently in such an ancestor simulation, rather than in the genuine historical civilization that later gives rise to an abundance of future people.</p>

<p>Not officially included in the argument I think, but commonly believed: both a) and b) seem pretty likely, ergo we should conclude we are in a simulation.</p>

<p>I don’t know about this. Here’s my counterargument:</p>

<ol>
  <li>‘Simulations’ here are people who are intentionally misled about their whereabouts in the universe. For the sake of argument, let’s use the term ‘simulation’ for all such people, including e.g. biological people who have been grown in Truman-show-esque situations.</li>
  <li>In the long run, the cost of running a simulation of a confused mind is probably similar to that of running a non-confused mind.</li>
  <li>Probably much, much less than 50% of the resources allocated to computing minds in the long run will be allocated to confused minds, because non-confused minds are generally more useful than confused minds. There are some uses for confused minds, but quite a lot of uses for non-confused minds. (This is debatable.) Of resources directed toward minds in the future, I’d guess less than a thousandth is directed toward confused minds.</li>
  <li>Thus on average, for a given apparent location in the universe, the majority of minds thinking they are in that location are correct. (I guess at at least a thousand to one.)</li>
  <li>For people in our situation to be majority simulations, this would have to be a vastly more simulated location than average, like &gt;1000x</li>
  <li>I agree there’s some merit to simulating ancestors, but 1000x more simulated than average is a lot - is it clear that we are that radically desirable a people to simulate? Perhaps, but also we haven’t thought much about the other people to simulate, or what will go in in the rest of the universe. Possibly we are radically over-salient to us. It’s true that we are a very few people in the history of what might be a very large set of people, at perhaps a causally relevant point. But is it clear that is a very, very strong reason to simulate some people in detail? It feels like it might be salient because it is what makes us stand out, and someone who has the most energy-efficient brain in the Milky Way would think that was the obviously especially strong reason to simulate a mind, etc.<!--ex--></li>
</ol>

<p>I’m not sure what I think in the end, but for me this pushes back against the intuition that it’s so radically cheap, surely someone will do it. For instance from Bostrom:</p>

<blockquote>
  <p>We noted that a rough approximation of the computational power of a planetary-mass computer is 1042 operations per second, and that assumes only already known nanotechnological designs, which are probably far from optimal. A single such a computer could simulate the entire mental history of humankind (call this an ancestor-simulation) by using less than one millionth of its processing power for one second. A posthuman civilization may eventually build an astronomical number of such computers. We can conclude that the computing power available to a posthuman civilization is sufficient to run a huge number of ancestor-simulations even it allocates only a minute fraction of its resources to that purpose. We can draw this conclusion even while leaving a substantial margin of error in all our estimates.</p>
</blockquote>

<p>Simulating history so far might be extremely cheap. But if there are finite resources and astronomically many extremely cheap things, only a few will be done.</p>

  </div><a class="u-url" href="/2024/03/03/are-we-so-good-to-simulate.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>


  <div class="wrapper">
    <!-- <div>
      <h2 class="footer-heading"><a href="/list.html">Full archive</a></h2>
    </div> -->

    <!-- <div>
      <h2 class="footer-heading">Search</h2>
<script async src="https://cse.google.com/cse.js?cx=06d4880e018d74eb0">
</script>
<div class="gcse-search"></div>
</div> -->


    <br>

    <h2 class="footer-heading"><a href="/">world spirit sock puppet</a></h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <p>Inclusive writings of Katja Grace</p>
        <a href="/list.html">Full archive</a>
        <br>
        <ul class="contact-list">
          <li class="p-name">
            <!--Katja Grace-->
            </li><ul class="social-media-list"><li><a href="https://www.twitter.com/KatjaGrace"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">KatjaGrace</span></a></li></ul>
<li><a class="u-email" href="mailto:katjasolveig@gmail.com">katjasolveig@gmail.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2">
        <!--<ul class="social-media-list"><li><a href="https://www.twitter.com/KatjaGrace"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">KatjaGrace</span></a></li></ul>
-->
      </div>

      <div class="footer-col footer-col-3">
        <h4 class="footer-heading">Search</h4>
<script async src="https://cse.google.com/cse.js?cx=06d4880e018d74eb0">
</script>
<div class="gcse-search"></div>
</div>
    </div>

  </div>


</footer>
</body>

</html>
