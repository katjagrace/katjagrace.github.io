<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Page 2 of 17 for world spirit sock puppet | Inclusive writings of Katja Grace</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="world spirit sock puppet" />
<meta name="author" content="Katja Grace" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Inclusive writings of Katja Grace" />
<meta property="og:description" content="Inclusive writings of Katja Grace" />
<link rel="canonical" href="http://localhost:4000/blog/page2/" />
<meta property="og:url" content="http://localhost:4000/blog/page2/" />
<meta property="og:site_name" content="world spirit sock puppet" />
<link rel="prev" href="http://localhost:4000/" />
<link rel="next" href="http://localhost:4000/blog/page3/" />
<script type="application/ld+json">
{"headline":"world spirit sock puppet","url":"http://localhost:4000/blog/page2/","author":{"@type":"Person","name":"Katja Grace"},"@type":"WebPage","description":"Inclusive writings of Katja Grace","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="world spirit sock puppet" /><!-- Twitter cards -->
  <meta name="twitter:site"    content="@KatjaGrace">
  <meta name="twitter:creator" content="@">
  <meta name="twitter:title"   content="">

  
  <meta name="twitter:description" content="Inclusive writings of Katja Grace">
  

  
  <meta name="twitter:card"  content="summary">
  <meta name="twitter:image" content="">
  
  <!-- end of Twitter cards -->
</head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">world spirit sock puppet</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <div class="home"><a href=/index.html><b>HOME</b></a> &mdash; <a href=/full.html>FULL</a> &mdash; <a href=/list.html>LIST</a> &mdash; <a href=/worldlypositions.html>WORLDLY POSITIONS</a> &mdash; <a href=/meteuphoric.html>METEUPHORIC</a>
<br>
<br>

<!-- This loops through the paginated posts -->
<ul class="post-list">
  
    <li>
      <h3>
        <a class="post-link" href="/2022/01/16/covid-considerations.html">
          Long covid: probably worth avoiding—some considerations</a><span class="post-meta"> Jan 16, 2022</span>
      </h3><!-----

You have some errors, warnings, or alerts. If you are using reckless mode, turn it off to see inline alerts.
* ERRORs: 0
* WARNINGs: 0
* ALERTS: 1

Conversion time: 2.305 seconds.


Using this Markdown file:

1. Paste this output into your source file.
2. See the notes and action items below regarding this conversion run.
3. Check the rendered output (headings, lists, code blocks, tables) for proper
   formatting and use a linkchecker before you publish this page.

Conversion notes:

* Docs to Markdown version 1.0β33
* Sat Jan 15 2022 20:53:11 GMT-0800 (PST)
* Source doc: Long covid blog post
* This document has images: check for >>>>>  gd2md-html alert:  inline image link in generated source and store images to your server. NOTE: Images in exported zip file from Google Docs may not appear in  the same order as they do in your doc. Please check the images!

**Notes on my continued eschewal of covid/Covid seems bad to get/ Covid sucks: let me count the ways**----->

<!--bwr I don't think you need to count the considerations-->

<p>I hear friends reasoning, “I’ll get covid eventually and long covid probably isn’t that bad; therefore it’s not worth much to avoid it now”. Here are some things informing my sense that that’s an error:</p>

<a href="/2022/01/16/covid-considerations.html" span class="post-meta">&#8594;</a></li>
  
    <li>
      <h3>
        <a class="post-link" href="/2022/01/14/preliminary-long-covid-survey.html">
          Survey supports ‘long covid is bad’ hypothesis (very tentative)</a><span class="post-meta"> Jan 14, 2022</span>
      </h3><p>I wanted more clues about whether really bad long covid outcomes were vanishingly rare (but concentrated a lot in my <a href="https://twitter.com/KatjaGrace/status/1480780277156773889">Twitter</a>) or whether for instance a large fraction of ‘brain fogs’ reported in datasets are anything like the horrors sometimes described. So I took my questions to <a href="https://app.positly.com/">Positly</a>, hoping that the set of people who would answer questions for money there was fairly random relative to covid outcomes.</p>

<p>I hope to write something more careful about this survey soon, especially if it is of interest, but figure the basic data is better to share sooner. This summary is not very careful, and may e.g. conflate slightly differently worded questions, or fail to exclude obviously confused answers, or slightly miscount.</p>

<p>This is a survey of ~230 <a href="https://app.positly.com/">Positly</a> survey takers in the US, all between 20 and 40 years old. Very few of the responses I’ve looked at seem incoherent or botlike, unlike those in the <a href="https://worldspiritsockpuppet.com/2020/11/06/why-trump.html">survey</a> I did around the time of the election.</p>

<a href="/2022/01/14/preliminary-long-covid-survey.html" span class="post-meta">&#8594;</a></li>
  
    <li>
      <h3>
        <a class="post-link" href="/2021/09/26/fire-alarms-and-social-inaction.html">
          Beyond fire alarms: freeing the groupstruck</a><span class="post-meta"> Sep 26, 2021</span>
      </h3><p>Crossposted from <a href="https://aiimpacts.org/beyond-fire-alarms-freeing-the-groupstruck/">AI Impacts</a></p>

<p><em>[Content warning: death in fires, death in machine apocalypse]</em></p>

<h2 id="no-fire-alarms-for-agi">‘No fire alarms for AGI’</h2>

<p>Eliezer Yudkowsky wrote that ‘<a href="https://intelligence.org/2017/10/13/fire-alarm/">there’s no fire alarm for Artificial General Intelligence</a>’, by which I think he meant: ‘there will be no future AI development that proves that artificial general intelligence (AGI) is a problem clearly enough that the world gets common knowledge (i.e. everyone knows that everyone knows, etc) that freaking out about AGI is socially acceptable instead of embarrassing.’</p>

<p>He calls this kind of event a ‘fire alarm’ because he posits that this is how fire alarms work: rather than alerting you to a fire, they primarily help by making it common knowledge that it has become socially acceptable to act on the potential fire.</p>

<p>He supports this view with a great 1968 study by Darley and Latané, in which they found that if you pipe a white plume of ‘smoke’ through a vent into a room where participants fill out surveys, a lone participant will quickly leave to report it, whereas a group of three (innocent) participants will tend to sit by in the haze for much longer[^1].</p>

<p><a href="https://www.youtube.com/watch?v=vjP22DpYYh8">Here’s</a> a video of a rerun[^2] of part of this experiment, if you want to see what people look like while they try to negotiate the dual dangers of fire and social awkwardness.</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/vjP22DpYYh8?start=107" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
<p><br /></p>

<a href="/2021/09/26/fire-alarms-and-social-inaction.html" span class="post-meta">&#8594;</a></li>
  
    <li>
      <h3>
        <a class="post-link" href="/2021/07/20/punishing-whats-right.html">
          Punishing the good</a><span class="post-meta"> Jul 20, 2021</span>
      </h3><p>Should you punish people for wronging others, or for making the wrong call about wronging others?</p>

<a href="/2021/07/20/punishing-whats-right.html" span class="post-meta">&#8594;</a></li>
  
    <li>
      <h3>
        <a class="post-link" href="/2021/07/15/lafayette-norms.html">
          Lafayette: empty traffic signals</a><span class="post-meta"> Jul 15, 2021</span>
      </h3><p>Seeking to cross a road on the walk into downtown Lafayette, instead of the normal pedestrian crossing situation, we met a button with a sign, ‘Push button to turn on warning lights’. I wondered, if I pressed it, would it then be my turn to cross? Or would there just be some warning lights? What was the difference? Do traffic buttons normally do something other than change the lights?</p>

<a href="/2021/07/15/lafayette-norms.html" span class="post-meta">&#8594;</a></li>
  
    <li>
      <h3>
        <a class="post-link" href="/2021/07/14/traffic-vessels.html">
          Lafayette: traffic vessels</a><span class="post-meta"> Jul 14, 2021</span>
      </h3><p>This week I’m in Lafayette, a town merely twenty-three minutes further from my San Franciscan office than my usual San Franciscan home, thanks to light rail. There are deer in the street and woods on the walk from the train to town.</p>

<a href="/2021/07/14/traffic-vessels.html" span class="post-meta">&#8594;</a></li>
  
    <li>
      <h3>
        <a class="post-link" href="/2021/07/12/typology-of-blog-posts.html">
          Typology of blog posts that don&#39;t always add anything clear and insightful</a><span class="post-meta"> Jul 12, 2021</span>
      </h3><p>I used to think a good blog post should basically be a description of a novel insight.</p>

<a href="/2021/07/12/typology-of-blog-posts.html" span class="post-meta">&#8594;</a></li>
  
    <li>
      <h3>
        <a class="post-link" href="/2021/06/29/do-incoherent-creatures-have-reason-to-be-coherent.html">
          Do incoherent entities have stronger reason to become more coherent than less?</a><span class="post-meta"> Jun 29, 2021</span>
      </h3><p>My understanding is that various ‘coherence arguments’ exist, of the form:</p>

<ol>
  <li>If your preferences diverged from being representable by a utility function in some way, then you would do strictly worse in some way than by having some kind of preferences that were representable by a utility function. For instance, you will lose money, for nothing.</li>
  <li>You have good reason not to do that / don’t do that / you should predict that reasonable creatures will stop doing that if they notice that they are doing it.</li>
</ol>

<a href="/2021/06/29/do-incoherent-creatures-have-reason-to-be-coherent.html" span class="post-meta">&#8594;</a></li>
  
    <li>
      <h3>
        <a class="post-link" href="/2021/06/06/holidaying-and-purpose.html">
          Holidaying and purpose</a><span class="post-meta"> Jun 06, 2021</span>
      </h3><p>I’m on holiday. A basic issue with holidays is that it feels more satisfying and meaningful to do purposeful things, but for a thing to actually serve a purpose, it often needs to pass a higher bar than a less purposeful thing does. In particular, you often have to finish a thing and do it well in order for it to achieve its purpose. And finishing things well is generally harder and less fun than starting them, and so in other ways contrary to holidaying.</p>

<a href="/2021/06/06/holidaying-and-purpose.html" span class="post-meta">&#8594;</a></li>
  
    <li>
      <h3>
        <a class="post-link" href="/2021/03/26/coherence-arguments-imply-a-force-for-goal-directed-behavior.html">
          Coherence arguments imply a force for goal-directed behavior</a><span class="post-meta"> Mar 26, 2021</span>
      </h3><p><em><em>Crossposted from <a href="https://aiimpacts.org/">AI Impacts</a></em></em></p>

<p><em>[Epistemic status: my current view, but I haven’t read all the stuff on this topic even in the LessWrong community, let alone more broadly.]</em></p>

<p>There is a line of thought that says that advanced AI will tend to be ‘goal-directed’—that is, consistently doing whatever makes certain favored outcomes more likely—and that this is to do with the ‘coherence arguments’. <a href="https://www.lesswrong.com/posts/NxF5G6CJiof6cemTw/coherence-arguments-do-not-imply-goal-directed-behavior">Rohin Shah</a>, and probably others<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup> , have argued against this. I want to argue against them.</p>

<!-- wp:heading -->
<h2>The old argument for coherence implying (worrisome) goal-directedness</h2>
<!-- /wp:heading -->

<p>I’d reconstruct the original argument that Rohin is arguing against as something like this (making no claim about my own beliefs here):</p>

<ul>
  <li><strong>‘Whatever things you care about, you are best off assigning consistent numerical values to them and maximizing the expected sum of those values’</strong> <br /> ‘Coherence arguments’<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote">2</a></sup> mean that if you don’t maximize ‘expected utility’ (EU)—that is, if you don’t make every choice in accordance with what gets the highest average score, given consistent preferability scores that you assign to all outcomes—then you will make strictly worse choices by your own lights than if you followed some alternate EU-maximizing strategy (at least in some situations, though they may not arise). For instance, you’ll be vulnerable to ‘<a href="https://www.oxfordreference.com/view/10.1093/oi/authority.20110803100205601">money-pumping</a>’—being predictably parted from your money for nothing.<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote">3</a></sup></li>
  <li><strong>‘Advanced AI will tend to do better things instead of worse things, by its own lights’</strong> <br />Advanced AI will tend to avoid options that are predictably strictly worse by its own lights, due to being highly optimized for making good choices (by some combination of external processes that produced it, its own efforts, and the selection pressure acting on its existence).</li>
  <li><strong>‘Therefore advanced AI will maximize EU, roughly’</strong> <br />Advanced AI will tend to be fairly coherent, at least to a level of approximation where becoming more coherent isn’t worth the cost.<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" class="footnote">4</a></sup> Which will probably be fairly coherent (e.g. close enough to coherent that <a href="https://arbital.com/p/optimized_agent_appears_coherent/">humans can’t anticipate the inconsistencies</a>).</li>
  <li><strong>‘Maximizing EU is pretty much the same as being goal-directed’</strong><br />To maximize expected utility is to pursue the goal of that which you have assigned higher utility to.<sup id="fnref:6" role="doc-noteref"><a href="#fn:6" class="footnote">5</a></sup></li>
</ul>

<p>And since the point of all this is to argue that advanced AI might be hard to deal with, note that we can get to that conclusion with:</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>For instance, Richard Ngo agrees <a href="https://www.lesswrong.com/posts/vphFJzK3mWA4PJKAg/coherent-behaviour-in-the-real-world-is-an-incoherent">here</a>, and Eric Drexler makes a related argument <a href="https://www.fhi.ox.ac.uk/wp-content/uploads/Reframing_Superintelligence_FHI-TR-2019-1.1-1.pdf">here</a>, section 6.4. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>Something something <a href="https://arbital.com/p/expected_utility_formalism/?l=7hh">This</a> has more on these arguments. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>I haven’t read all of this, and don’t yet see watertight versions of these arguments, but this is not the time I’m going to get into that. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:5" role="doc-endnote">
      <p>Assuming being ‘more coherent’ is meaningful and better than being ‘less coherent’, granting that one is not coherent, which sounds plausible, but which I haven’t got into. One argument against is that if you are incoherent at all, then it looks to me like you can logically evaluate any bundle of things at any price. Which would seem to make all incoherences identical—much like how all logical contradictions equivalently lead to every belief. However this seems unlikely to predict well how creatures behave in practice if they have an incoherent preferences. <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:6" role="doc-endnote">
      <p>This isn’t quite right, since ‘goal’ suggests one outcome that is being pursued ahead of all others, whereas EU-maximizing implies that all possible outcomes have an ordering, and you care about getting higher ones in general, not just the top one above all others, but this doesn’t seem like a particularly relevant distinction here. <a href="#fnref:6" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
<a href="/2021/03/26/coherence-arguments-imply-a-force-for-goal-directed-behavior.html" span class="post-meta">&#8594;</a></li>
  
</ul>

<!-- Pagination links -->
<div class="pagination">
  
    <a href="/" class="previous">
      Previous
    </a>
  
  <span class="page_number ">
    Page: 2 of 17
  </span>
  
    <a href="/blog/page3/" class="next">Next</a>
  
</div>


<!-- Feel free to add content and custom Front Matter to this file.
To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults [message that came with blog I think]

Originally I had a file index.markdown, which I replaced with this one in order to try to get pagination to work.
I also added two loops to a mostly empty page for that.-->


  &nbsp;

  <p class="rss-subscribe">subscribe <a href="/feed.xml">via RSS feed</a> or <a href="/subscribe-form.html">via email</a></p>

</div>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">world spirit sock puppet</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Katja Grace</li><li><a class="u-email" href="mailto:katjasolveig@gmail.com">katjasolveig@gmail.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://www.twitter.com/KatjaGrace"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">KatjaGrace</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>Inclusive writings of Katja Grace</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
