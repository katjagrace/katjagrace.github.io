<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0">
<channel>
 <title>world spirit sock puppet</title>
 <description>Inclusive writings of Katja Grace</description>
 <link>http://localhost:4000</link>
 <lastBuildDate>Tue, 17 Nov 2020 22:18:31 -0800</lastBuildDate>
 <pubDate>Tue, 17 Nov 2020 22:18:31 -0800</pubDate>
 <ttl>1800</ttl>

 
 <item>
  <title>Misalignment and misuse: whose values are manifest?</title>
  <description>
    <p><emph>Crossposted via RSS from worldspiritsockpuppet.com; faithful transmission uncertain</emph></p>
    <br>
    <p>AI related disasters are often categorized as involving misaligned AI, or misuse, or accident. Where:</p>
<ul>
  <li>misuse means the bad outcomes were wanted by the people involved,</li>
  <li>misalignment means the bad outcomes were wanted by AI (and not by its human creators), and</li>
  <li>accident means that the bad outcomes were not wanted by those in power but happened anyway due to error.</li>
</ul>

<p>In thinking about specific scenarios, these concepts seem less helpful.</p>

<p>I think a likely scenario leading to bad outcomes is that AI can be made which gives a set of people things they want, at the expense of future or distant resources that the relevant people do not care about or do not own.</p>

<p>For example, consider autonomous business strategizing AI systems that are profitable additions to many companies, but in the long run accrue resources and influence and really just want certain businesses to nominally succeed, resulting in a worthless future. Suppose Bob is considering whether to get a business strategizing AI for his business. It will make the difference between his business thriving and struggling, which will change his life. He suspects that within several hundred years, if this sort of thing continues, the AI systems will control everything. Bob probably doesn’t hesitate, in the way that businesses don’t hesitate to use gas vehicles even if the people involved genuinely think that climate change will be a massive catastrophe in hundreds of years.</p>

<p>When the business strategizing AI systems finally plough all of the resources in the universe into a host of thriving 21st Century businesses, was this misuse or misalignment or accident? The strange new values that were satisfied were those of the AI systems, but the entire outcome only happened because people like Bob chose it knowingly (let’s say). Bob liked it more than the long glorious human future where his business was less good. That sounds like misuse. Yet also in a system of many people, letting this decision fall to Bob may well have been an accident on the part of others, such as the technology’s makers or legislators.</p>

<p>Outcomes are the result of the interplay of choices, driven by different values. Thus it isn’t necessarily sensical to think of them as flowing from one entity’s values or another’s. Here, AI technology created a better option for both Bob and some newly-minted misaligned AI values that it also created—‘Bob has a great business, AI gets the future’—and that option was worse for the rest of the world. They chose it together, and the choice needed both Bob to be a misuser and the AI to be misaligned. But this isn’t a weird corner case, this is a natural way for the future to be destroyed in an economy.</p>

<p><em>Thanks to Joe Carlsmith for conversation leading to this post.</em></p>

  </description>
  <link>/2020/11/13/misalignment-and-misuse.html</link>
  <guid isPermaLink="true">http://localhost:4000/2020/11/13/misalignment-and-misuse.html</guid>
  <pubDate>Fri, 13 Nov 2020 00:25:04 -0800</pubDate>
 </item>
 
 <item>
  <title>Tweet markets for impersonal truth tracking?</title>
  <description>
    <p><emph>Crossposted via RSS from worldspiritsockpuppet.com; faithful transmission uncertain</emph></p>
    <br>
    <p>Should social media label statements as false, misleading or contested?</p>

<p>Let’s approach it from the perspective of what would make the world best, rather than e.g. what rights do the social media companies have, as owners of the social media companies.</p>

<p>The basic upside seems to be that pragmatically, people share all kinds of false things on social media, and that leads to badness, and this slows that down.</p>

<p>The basic problem with it is that maybe we can’t distinguish worlds where social media companies label false things as false, and those where they label things they don’t like as false, or things that aren’t endorsed by other ‘official’ entities. So maybe we don’t want such companies to have the job of deciding what is considered true or false, because a) we don’t trust them enough to give them this sacred and highly pressured job forever, or b) we don’t expect everyone to trust them forever, and it would be nice to have better recourse when disagreement appears than ‘but I believe them’.</p>

<p>If there were a way to systematically inhibit or label false content based on its falseness directly, rather than via a person’s judgment, that would be an interesting solution that perhaps everyone reasonable would agree to add. If prediction markets were way more ubiquitous, each contentious propositional Tweet could say under it the market odds for the claim.</p>

<p>Or what if Twitter itself were a prediction market, trading in Twitter visibility? For just-posted Tweets, instead of liking them, you can bet your own cred on them. Then a while later, they are shown again and people can vote on whether they turned out right and you win or lose cred. Then your total cred determines how much visibility your own Tweets get.</p>

<p>It seems like this would solve:</p>
<ul>
  <li>the problem for prediction markets where it is illegal to bet money and hard to be excited about fake money</li>
  <li>the problem for prediction markets where it’s annoying to go somewhere to predict things when you are doing something else, like looking at Twitter</li>
  <li>the problem for Twitter where it is full of fake claims</li>
  <li>the problem for Twitter users where they have to listen to fake claims all the time, and worry about whether all kinds of things are true or not</li>
</ul>

<p>It would be pretty imperfect, since it throws the gavel to future Twitter users, but perhaps they are an improvement on the status quo, or on the status quo without the social media platforms themselves making judgments.</p>

  </description>
  <link>/2020/11/09/tweet-markets.html</link>
  <guid isPermaLink="true">http://localhost:4000/2020/11/09/tweet-markets.html</guid>
  <pubDate>Mon, 09 Nov 2020 10:01:22 -0800</pubDate>
 </item>
 
 <item>
  <title>Automated intelligence is not AI</title>
  <description>
    <p><emph>Crossposted via RSS from worldspiritsockpuppet.com; faithful transmission uncertain</emph></p>
    <br>
    <p>Sometimes we think of ‘artificial intelligence’ as whatever technology ultimately automates human cognitive labor.</p>

<p>I question this equivalence, looking at past automation. In practice human cognitive labor is replaced by things that don’t seem at all cognitive, or like what we otherwise mean by AI.</p>

<p>Some examples:</p>
<ol>
  <li>Early in the existence of bread, it might have been toasted by someone holding it close to a fire and repeatedly observing it and recognizing its level of doneness and adjusting. Now we have machines that hold the bread exactly the right distance away from a predictable heat source for a perfect amount of time. You could say that the shape of the object embodies a lot of intelligence, or that intelligence went into creating this ideal but non-intelligent tool.</li>
  <li>Self-cleaning ovens replace humans cleaning ovens. Humans clean ovens with a lot of thought—looking at and identifying different materials and forming and following plans to remove some of them. Ovens clean themselves by getting very hot.</li>
  <li>Carving a rabbit out of chocolate takes knowledge of a rabbit’s details, along with knowledge of how to move your hands to translate such details into chocolate with a knife. A rabbit mold automates this work, and while this route may still involve intelligence in the melting and pouring of the chocolate, all rabbit knowledge is now implicit in the shape of the tool, though I think nobody would call a rabbit-shaped tin ‘artificial intelligence’.</li>
  <li>Human pouring of orange juice into glasses involves various mental skills. For instance, classifying orange juice and glasses and judging how they relate to one another in space, and moving them while keeping an eye on this. Automatic orange juice pouring involves for instance a button that can only be pressed with a glass when the glass is in a narrow range of locations, which opens an orange juice faucet running into a spot common to all the possible glass-locations.</li>
</ol>

<p>Some of this is that humans use intelligence where they can use some other resource, because it is cheap on the margin where the other resource is expensive. For instance, to get toast, you could just leave a lot of bread at different distances then eat the one that is good. That is bread-expensive and human-intelligence-cheap (once you come up with the plan at least). But humans had lots of intelligence and not much bread. And if later we automate a task like this, before we have computers that can act very similarly to brains, then the alternate procedure will tend to be one that replaces human thought with something that actually is cheap at the time, such as metal.</p>

<p>I think a lot of this is that to deal with a given problem you can either use flexible intelligence in the moment, or you can have an inflexible system that happens to be just what you need. Often you will start out using the flexible intelligence, because being flexible it is useful for lots of things, so you have some sitting around for everything, whereas you don’t have an inflexible system that happens to be just what you need. But if a problem seems to be happening a lot, it can become worth investing the up-front cost of getting the ideal tool, to free up your flexible intelligence again.</p>

  </description>
  <link>/2020/11/01/automating-intelligence.html</link>
  <guid isPermaLink="true">http://localhost:4000/2020/11/01/automating-intelligence.html</guid>
  <pubDate>Sun, 01 Nov 2020 01:58:21 -0700</pubDate>
 </item>
 
 <item>
  <title>Whence the symptoms of social media?</title>
  <description>
    <p><emph>Crossposted via RSS from worldspiritsockpuppet.com; faithful transmission uncertain</emph></p>
    <br>
    <p>A thing I liked about <em>The Social Dilemma</em> was the evocative image of oneself being in an epic contest for one’s attention with a massive and sophisticated data-nourished machine, tended by teams of manipulation experts. The hopelessness of the usual strategies—like spur-of-the-moment deciding to ‘try to use social media less’—in the face of such power seems clear.</p>

<p>But <a href="https://worldspiritsockpuppet.com/2020/10/26/the-social-dilemma-review.html">another</a> question I have is whether this basic story of our situation—that powerful forces are fluently manipulating our behavior—is true.</p>

<p>Some contrary observations from my own life:</p>
<ul>
  <li><strong>The phenomenon of spending way too long doing apparently pointless things on my phone seems to be at least as often caused by things that are not massively honed to manipulate me.</strong> For instance, I recently play a lot of <a href="https://en.wikipedia.org/wiki/Nonogram">nonograms</a>, a kind of visual logic puzzle that was <a href="https://en.wikipedia.org/wiki/Nonogram#History">invented by two people independently in the 80s</a> and which I play in one of many somewhat awkward-to-use phone apps, I assume made by small teams mostly focused on making the app work smoothly. My sense is that if I didn’t have nonograms style games or social media or news to scroll through, then I would still often idly pick up my phone and draw, or read books, or learn Spanish, or memorize geographic facts, or scroll through just anything on offer to scroll through (I also do these kinds of things already). So my guess is that it is my phone’s responsiveness and portability and tendency to do complicated things if you press buttons on it, that makes it a risk for time consumption. Facebook’s efforts to grab my attention probably don’t hurt, but I don’t feel like they are most of the explanation for phone-overuse in my own life.</li>
  <li><strong>Notifications seem clumsy and costly.</strong> They do grab my attention pretty straightforwardly, but this strategy appears to have about the sophistication of going up to someone and tapping them on the shoulder continually, when you have a sufficiently valuable relationship that they can’t just break it off you annoy them too much. In that case it isn’t some genius manipulation technique, it’s just burning through the goodwill the services have gathered by being valuable in other ways. If I get unnecessary notifications, I am often annoyed and try to stop them or destroy the thing causing them.</li>
  <li><strong>I do often scroll through feeds for longer than I might have planned to, but the same goes for non-manipulatively-honed feeds.</strong> For instance when I do a Google Image search for skin infections, or open some random report and forget why I’m looking at it. So I think scrolling down things might be a pretty natural behavior for things that haven’t finished yet, and are interesting at all (but maybe not so interesting that one is, you know, awake..)<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup></li>
  <li><strong>A thing that feels attractive about Facebook is that one wants to look at things that other people are looking at.</strong> (Thus for instance reading books and blog posts that just came out over older, better ones.) Social media have this, but presumably not much more than newspapers did before, since a greater fraction of the world was looking at the same newspaper before.</li>
</ul>

<p>In sum, I offer the alternate theory that various technology companies have combined:</p>
<ul>
  <li>pinging people</li>
  <li>about things they are at least somewhat interested in</li>
  <li>that everyone is looking at</li>
  <li>situated in an indefinite scroll</li>
  <li>on a responsive, detailed pocket button-box</li>
</ul>

<p>…and that most of the attention-suck and influence that we see is about those things, not about the hidden algorithmic optimizing forces that Facebook might have.</p>

<hr />

<p><em>(<a href="https://worldspiritsockpuppet.com/2020/10/26/the-social-dilemma-review.html">Part 1 of Social Dilemma review</a>)</em></p>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>My boyfriend offers alternate theory, that my scrolling instinct comes from Facebook. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>

  </description>
  <link>/2020/10/27/social-dilemma-2.html</link>
  <guid isPermaLink="true">http://localhost:4000/2020/10/27/social-dilemma-2.html</guid>
  <pubDate>Tue, 27 Oct 2020 00:22:12 -0700</pubDate>
 </item>
 
 <item>
  <title>But what kinds of puppets are we?</title>
  <description>
    <p><emph>Crossposted via RSS from worldspiritsockpuppet.com; faithful transmission uncertain</emph></p>
    <br>
    <p>I watched <a href="https://www.thesocialdilemma.com/">The Social Dilemma</a> last night. I took the problem that it warned of to be the following:</p>

<ol>
  <li>Social media and similar online services make their money by <a href="https://worldspiritsockpuppet.com/2020/10/14/the-bads-of-ads.html">selling your attention to advertisers</a></li>
  <li>These companies put vast optimization effort into manipulating you, to extract more attention</li>
  <li>This means your behavior and attention is probably very shaped by these forces (which you can perhaps confirm by noting your own readiness to scroll through stuff on your phone)</li>
</ol>

<p>This seems broadly plausible and bad, but I wonder if it isn’t quite that bad.</p>

<p>I heard the film as suggesting that your behavior and thoughts in general are being twisted by these forces. But lets distinguish between a system where huge resources are going into keeping you scrolling say—at which point an advertiser will pay for their shot at persuading you—and a system where those resources are going into manipulating you directly to do the things that the advertiser would like. In the first case, maybe you look at your phone too much, but there isn’t a clear pressure on your opinions or behavior besides pro phone. In the second case, maybe you end up with whatever opinions and actions someone paid the most for (this all supposing the system works). Let’s call these distorted-looking and distorted-acting.</p>

<p>While watching I interpreted the film suggesting the sort of broad manipulation that would come with distorted-acting, but thinking about it afterwards, isn’t the kind of optimization going on with social media actually distorted-looking? (Followed by whatever optimization the advertisers do to get you to do what they want, which I guess is of a kind with what they have always done, so at least not a new experimental horror.) I actually don’t really know. And maybe it isn’t a bright distinction.</p>

<p>Maybe optimization for you <em>clicking</em> on ads should be a different category (i.e. ‘distorted-clicking’). This seems close to distorted-looking, in that it isn’t directly seeking to manipulate your behavior outside of your phone session, but a big step closer to distorted-acting, since you have been set off toward whatever you have ultimately been targeted to buy.</p>

<p>I was at first thinking that distorted-looking was safer than distorted-acting. But distorted-looking forces probably do also distort your opinions and actions. For instance, as the film suggested, you are likely to look more if you get interested in something that there is a lot of content on, or something that upsets you and traps your attention.</p>

<p>I could imagine distorted-looking actually being worse than distorted-acting: when your opinion can be bought, the change in it is presumably what someone would want. Whereas when your opinion is manipulated as a weird side effect of someone trying to get you to look more, then it could be any random thing, which might be terrible.(Or would there be such weird side effects in both cases anyway?)</p>

  </description>
  <link>/2020/10/26/the-social-dilemma-review.html</link>
  <guid isPermaLink="true">http://localhost:4000/2020/10/26/the-social-dilemma-review.html</guid>
  <pubDate>Mon, 26 Oct 2020 00:52:20 -0700</pubDate>
 </item>
 
 <item>
  <title>Yet another world spirit sock puppet</title>
  <description>
    <p><emph>Crossposted via RSS from worldspiritsockpuppet.com; faithful transmission uncertain</emph></p>
    <br>
    <p>I have almost successfully made and made decent <a href="worldspiritsockpuppet.com">this here</a> my new blog, in spite of little pre-existing familiarity with relevant tools beyond things like persistence in the face of adversity and Googling things. I don’t fully understand how it works, but it is a different and freer non-understanding than with Wordpress or Tumblr. This blog is more mine to have mis-built and to go back and fix. It is like not understanding why your cake is still a liquid rather than like not understanding why your printer isn’t recognized by your computer.</p>

<p>My plan is to blog at <a href="worldspiritsockpuppet.com">worldspiritsockpuppet.com</a> now, and cross-post to my older blogs the subset of posts that fit there.</p>

<p>The main remaining thing is to add comments. If anyone has views about how those should be, er, tweet at me?</p>

  </description>
  <link>/2020/10/24/new-blog.html</link>
  <guid isPermaLink="true">http://localhost:4000/2020/10/24/new-blog.html</guid>
  <pubDate>Sat, 24 Oct 2020 22:11:19 -0700</pubDate>
 </item>
 
 <item>
  <title>The bads of ads</title>
  <description>
    <p><emph>Crossposted via RSS from worldspiritsockpuppet.com; faithful transmission uncertain</emph></p>
    <br>
    <p>In London at the start of the year, perhaps there was more advertising than there usually is in my life, because I found its presence disgusting and upsetting. Could I not use public transport without having my mind intruded upon continually by trite performative questions?</p>

<p><img src="https://worldspiritsockpuppet.com/assets/eendra-underground-ads.jpg" alt="London underground" style="margin:25px 0px" /></p>

<p>Sometimes I fantasize about a future where stealing someone’s attention to suggest for the fourteenth time that they watch your awful-looking play is rightly looked upon as akin to picking their pocket.</p>

<p>Stepping back, advertising is widely found to be a distasteful activity. But I think it is helpful to distinguish the different unpleasant flavors potentially involved (and often not involved—there is good advertising):</p>

<ol>
  <li>
    <p><strong>Mind manipulation</strong>: Advertising is famous for uncooperatively manipulating people’s beliefs and values in whatever way makes them more likely to pay money somehow. For instance, deceptively encouraging the belief that everyone uses a certain product, or trying to spark unwanted wants.</p>

    <p><img src="https://worldspiritsockpuppet.com/assets/markham-ad-paint.jpg" alt="Painting an ad" style="margin:25px 0px" /></p>
  </li>
  <li>
    <p><strong>Zero-sumness</strong>: To the extent advertising is aimed at raising the name recognition and thus market share of one product over its similar rivals, it is zero or negative sum: burning effort on both sides and the attention of the customer for no overall value.</p>

    <p><img src="https://worldspiritsockpuppet.com/assets/subiyanto-nestle-ad.jpg" height="495" /> <img src="https://worldspiritsockpuppet.com/assets/weir-coke-ad.jpg" height="495" /></p>
  </li>
  <li>
    <p><strong>Theft of a precious thing</strong>: Attention is arguably one of the best things you have, and its protection arguably worthy of great effort. In cases where it is vulnerable—for instance because you are outside and so do not personally control everything you might look at or hear—advertising is the shameless snatching of it. This might be naively done, in the same way that a person may naively steal silverware assuming that it is theirs to take because nothing is stopping them.</p>

    <p><img src="https://worldspiritsockpuppet.com/assets/williamsantos-underground.png" alt="London underground" /></p>
  </li>
  <li>
    <p><strong>Cultural poison</strong>: Culture and the common consciousness are an organic dance of the multitude of voices and experiences in society. In the name of advertising, huge amounts of effort and money flow into amplifying fake voices, designed to warp perceptions–and therefore the shared world–to ready them for exploitation. Advertising can be a large fraction of the voices a person hears. It can draw social creatures into its thin world. And in this way, it goes beyond manipulating the minds of those who listen to it. Through those minds it can warp the whole shared world, even for those who don’t listen firsthand. Advertising shifts your conception of what you can do, and what other people are doing, and what you should pay attention to. It presents role models, designed entirely for someone else’s profit. It saturates the central gathering places with inanity, as long as that might sell something.</p>

    <p><img src="https://worldspiritsockpuppet.com/assets/geib-ads.jpg" alt="Outdoor ads over darkened figures" style="margin:25px 0px" /></p>
  </li>
  <li>
    <p><strong>Market failure</strong>: Ideally, whoever my attention is worth most to would get it, regardless of whether it was initially stolen. For instance, if I have better uses for my attention than advertising, hopefully I will pay more to have it back than the advertiser expects to make by advertising to me. So we will be able to make a trade, and I’ll get my attention back. In practice this is probably too complicated, since so many tiny transactions are needed. E.g. the best message for me to see, if I have to see a message, when sitting on a train, is probably something fairly different from what I do see. It is also probably worth me paying a small sum to each person who would advertise at me to just see a blank wall instead. But it is hard for them to collect that money from each person. And in cases where the advertiser was just a random attention thief and didn’t have some special right to my attention, if I were to pay one to leave me alone, another one might immediately replace them.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup></p>

    <p><img src="https://worldspiritsockpuppet.com/assets/clear-ad-wu.jpg" alt="Underground ads over crowd" style="margin:25px 0px" /></p>
  </li>
  <li>
    <p><strong>Ugliness</strong>: At the object level, advertising is often clearly detracting from the beauty of a place.</p>

    <p><img src="https://worldspiritsockpuppet.com/assets/negspace-ads.jpg" alt="Ads overwhelming buildings" style="margin:25px 0px" /></p>
  </li>
</ol>

<p>These aren’t necessarily distinct—to the extent ugliness is bad, say, one might expect that it is related to some market failure. But they are different reasons for disliking a thing-a person can hate something ugly while having no strong view on the perfection of ideal markets.</p>

<p>What would good and ethical advertising look like? Maybe I decide that I want to be advertised to now, and go to my preferred advertising venue. I see a series of beautiful messages about things that are actively helpful for me to know. I can downvote ads if I don’t like the picture of the world that they are feeding into my brain, or the apparent uncooperativeness of their message. I leave advertising time feeling inspired and happy.</p>

<p><img src="https://worldspiritsockpuppet.com/assets/newstory-ads.jpg" alt="Ads: we are building a new story" style="margin:25px 0px" /></p>

<hr />

<p>Images: <a href="https://unsplash.com/photos/QG7Wkq2ZrpE">London Underground: Mona Eendra</a>, <a href="https://www.pexels.com/photo/man-painting-wall-2448522/">painting ads: Megan Markham</a>, <a href="https://www.pexels.com/photo/woman-wearing-a-face-mask-on-the-subway-4429291/">Nescafe ad: Ketut Subiyanto</a>, <a href="https://unsplash.com/photos/SUi9mYSVTyc">Coca-Cola: Hamish Weir</a>, <a href="https://unsplash.com/photos/6b8I4nxXPb0">London Underground again: Willam Santos</a>, <a href="https://www.pexels.com/photo/people-waiting-for-the-red-bus-to-pass-3220846/">figures in shade under ad: David Geib</a>, <a href="https://www.pexels.com/photo/people-standing-inside-train-3380873/">Clear ad in train: Life of Wu</a>, <a href="https://www.pexels.com/photo/light-london-adverts-piccadilly-circus-34639/">Piccadilly Circus: Negative Space</a>, <a href="https://unsplash.com/photos/xennYrcP3aM">Building a new story: Wilhelm Gunkel</a>.</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>For advertising in specific public locations, I could in principle pay by buying up the billboard or whatever and leaving it blank. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>

  </description>
  <link>/2020/10/13/the-bads-of-ads.html</link>
  <guid isPermaLink="true">http://localhost:4000/2020/10/13/the-bads-of-ads.html</guid>
  <pubDate>Tue, 13 Oct 2020 22:30:00 -0700</pubDate>
 </item>
 

</channel>
</rss>
