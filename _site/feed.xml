<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2025-05-19T21:43:19-07:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">world spirit sock puppet</title><subtitle>Inclusive writings of Katja Grace</subtitle><author><name>Katja Grace</name></author><entry><title type="html">Mental software updates</title><link href="http://localhost:4000/2025/02/25/mental-software-updates.html" rel="alternate" type="text/html" title="Mental software updates" /><published>2025-02-25T22:00:00-08:00</published><updated>2025-02-25T22:00:00-08:00</updated><id>http://localhost:4000/2025/02/25/mental-software-updates</id><content type="html" xml:base="http://localhost:4000/2025/02/25/mental-software-updates.html">&lt;p&gt;Brains are like computers in that the hardware can do all kinds of stuff in principle, but each one tends to run through some particular patterns of activity repeatedly. For computers you can change this by changing programs. What are big ways brain ‘software’ changes?&lt;!--ex--&gt;&lt;/p&gt;

&lt;p&gt;Some I can think of:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Intentional practice of different styles of thinking (e.g. meditation)&lt;/li&gt;
  &lt;li&gt;Intentional practice of different trains of thought in response to specific stimuli (e.g. CBT, self-talk)&lt;/li&gt;
  &lt;li&gt;Changing the high level situation, where your brain automatically has different patterns for each (e.g. if you go from feeling like a child to like an adult maybe a lot of patterns change)&lt;/li&gt;
  &lt;li&gt;A change in a major explicit belief (e.g. if you go from expecting your project to work out to believing otherwise, your patterns of attention might naturally change)&lt;/li&gt;
  &lt;li&gt;Learning that the world isn’t as you intuited (e.g. if you are constantly worrying about people wronging you, but everyone is kind to you, this worry might become unappealing)&lt;/li&gt;
  &lt;li&gt;Intense experiences causing inaccurate updating (e.g. trauma)&lt;/li&gt;
  &lt;li&gt;Identifying differently (e.g. if I think of myself as a good student, I might have different mental patterns around studying than when I thought of myself as a bad student)&lt;/li&gt;
  &lt;li&gt;Adopting a new goal (e.g. deciding to be a musician)&lt;/li&gt;
  &lt;li&gt;Getting a new responsibility (e.g. a child)&lt;/li&gt;
  &lt;li&gt;Getting a new obsession (e.g. a crush, a hobby)&lt;/li&gt;
  &lt;li&gt;Changing social groups (e.g. among jokers it is more tempting to think of jokes, though in my experience among philosophers it might have been less tempting to think of philosophy)&lt;/li&gt;
  &lt;li&gt;Interacting with a really compelling person&lt;/li&gt;
  &lt;li&gt;Drugs (e.g. alcohol, adderall, LSD both short term and long-term)&lt;/li&gt;
  &lt;li&gt;Religion, somehow&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I feel like people talk about many of these as important, but not in one view. I rarely hear someone say, “My brain software seems suboptimal, what are my options for changing it?”, then go down the list. Instead I suppose one hears from a friend that this book helped them, or one decides to have a therapist, and the book or therapist turns out to be one that focuses on CBT, so one does that. Or one changes social groups or responsibilities for some other reason, then remarks that this was a good or bad side-effect. Maybe that makes sense—‘stuff my brain habitually does’ is pretty broad. &lt;br /&gt;
 &lt;br /&gt;
 I’d be interested to know which things do in practice change people’s mental patterns the most.&lt;/p&gt;</content><author><name>Katja Grace</name></author><category term="meteuphoric" /><summary type="html">Brains are like computers in that the hardware can do all kinds of stuff in principle, but each one tends to run through some particular patterns of activity repeatedly. For computers you can change this by changing programs. What are big ways brain ‘software’ changes?</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://substackcdn.com/image/fetch/w_320,h_213,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_center/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffc23904e-f4ac-435a-9348-3c5141299a45_591x480.jpeg" /><media:content medium="image" url="https://substackcdn.com/image/fetch/w_320,h_213,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_center/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffc23904e-f4ac-435a-9348-3c5141299a45_591x480.jpeg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Winning the power to lose</title><link href="http://localhost:4000/2024/11/10/winning-the-power-to-lose.html" rel="alternate" type="text/html" title="Winning the power to lose" /><published>2024-11-10T22:00:00-08:00</published><updated>2024-11-10T22:00:00-08:00</updated><id>http://localhost:4000/2024/11/10/winning-the-power-to-lose</id><content type="html" xml:base="http://localhost:4000/2024/11/10/winning-the-power-to-lose.html">&lt;p&gt;Have the Accelerationists won?&lt;/p&gt;

&lt;p&gt;Last November Kevin Roose &lt;a href=&quot;https://www.nytimes.com/2023/11/22/technology/openai-board-capitalists.html&quot;&gt;announced&lt;/a&gt; that those in favor of going fast on AI had now won against those favoring caution, with the reinstatement of Sam Altman at OpenAI. Let’s ignore whether Kevin’s was a good description of the world, and deal with a more basic question: if it were so—i.e. if Team Acceleration would control the acceleration from here on out—what kind of win was it they won?&lt;!--ex--&gt;&lt;/p&gt;

&lt;p&gt;It seems to me that they would have probably won in the same sense that your dog has won if she escapes onto the road. She won the power contest with you and is probably feeling good at this moment, but if she does actually like being alive, and just has different ideas about how safe the road is, or wasn’t focused on anything so abstract as that, then whether she ultimately wins or loses depends on who’s factually right about the road.&lt;/p&gt;

&lt;p&gt;In disagreements where both sides want the same outcome, and disagree on what’s going to happen, then either side might win a tussle over the steering wheel, but all must win or lose the real game together. The real game is played against reality.&lt;/p&gt;

&lt;p&gt;Another vivid image of this dynamic in my mind: when I was about twelve and being driven home from a family holiday, my little brother kept taking his seatbelt off beside me, and I kept putting it on again. This was annoying for both of us, and we probably each felt like we were righteously winning each time we were in the lead. That lead was mine at the moment that our car was substantially shortened by an oncoming van. My brother lost the contest for power, but he won the real game—he stayed in his seat and is now a healthy adult with his own presumably miscalibratedly power-hungry child. We both won the real game.&lt;/p&gt;

&lt;p&gt;(These things are complicated by probability. I didn’t think we would be in a crash, just that it was likely enough to be worth wearing a seatbelt. I don’t think AI will definitely destroy humanity, just that it is likely enough to proceed with caution.)&lt;/p&gt;

&lt;p&gt;When everyone wins or loses together in the real game, it is in all of our interests if whoever is making choices is more factually right about the situation. So if someone grabs the steering wheel and you know nothing about who is correct, it’s anyone’s guess whether this is good news even for the party who grabbed it. It looks like a win for them, but it is as likely as not a loss if we look at the real outcomes rather than immediate power.&lt;/p&gt;

&lt;p&gt;This is not a general point about all power contests—most are not like this: they really are about opposing sides getting more of what they want at one another’s expense. But with AI risk, the stakes put most of us on the same side: we all benefit from a great future, and we all benefit from not being dead. If AI is scuttled over no real risk, that will be a loss for concerned and unconcerned alike. And similarly but worse if AI ends humanity—the ‘winning’ side won’t be any better off than the ‘losing side’. This is infighting on the same team over what strategy gets us there best. There is a real empirical answer. Whichever side is further from that answer is kicking own goals every time they get power.&lt;/p&gt;

&lt;p&gt;Luckily I don’t think the Accelerationists have won control of the wheel, which in my opinion improves their chances of winning the future!&lt;/p&gt;</content><author><name>Katja Grace</name></author><category term="meteuphoric" /><category term="ai" /><summary type="html">Have the Accelerationists won? Last November Kevin Roose announced that those in favor of going fast on AI had now won against those favoring caution, with the reinstatement of Sam Altman at OpenAI. Let’s ignore whether Kevin’s was a good description of the world, and deal with a more basic question: if it were so—i.e. if Team Acceleration would control the acceleration from here on out—what kind of win was it they won?</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://substackcdn.com/image/fetch/w_320,h_213,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_center/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F19953237-de7b-4d71-8056-1a3131159068_1024x1024.png" /><media:content medium="image" url="https://substackcdn.com/image/fetch/w_320,h_213,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_center/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F19953237-de7b-4d71-8056-1a3131159068_1024x1024.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Ten arguments that AI is an existential risk</title><link href="http://localhost:4000/2024/08/14/ten-arguments-that-ai-is-an-existential-risk-cp.html" rel="alternate" type="text/html" title="Ten arguments that AI is an existential risk" /><published>2024-08-14T15:16:00-07:00</published><updated>2024-08-14T15:16:00-07:00</updated><id>http://localhost:4000/2024/08/14/ten-arguments-that-ai-is-an-existential-risk-cp</id><content type="html" xml:base="http://localhost:4000/2024/08/14/ten-arguments-that-ai-is-an-existential-risk-cp.html">&lt;p&gt;You can read &lt;a href=&quot;https://blog.aiimpacts.org/p/ten-arguments-that-ai-is-an-existential&quot;&gt;Ten arguments that AI is an existential risk&lt;/a&gt; by Nathan Young and I at the &lt;a href=&quot;https://blog.aiimpacts.org&quot;&gt;AI Impacts Blog&lt;/a&gt;.&lt;/p&gt;</content><author><name>Katja Grace</name></author><category term="ai" /><summary type="html">You can read Ten arguments that AI is an existential risk by Nathan Young and I at the AI Impacts Blog.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://wiki.aiimpacts.org/_media/arguments_for_ai_risk/list_of_arguments_that_ai_poses_an_xrisk/detail_from_the_coronation_of_henry_vi.jpg?w=300&amp;h=278&amp;tok=befa2a" /><media:content medium="image" url="https://wiki.aiimpacts.org/_media/arguments_for_ai_risk/list_of_arguments_that_ai_poses_an_xrisk/detail_from_the_coronation_of_henry_vi.jpg?w=300&amp;h=278&amp;tok=befa2a" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Secondary forces of debt</title><link href="http://localhost:4000/2024/06/27/secondary-forces-of-debt.html" rel="alternate" type="text/html" title="Secondary forces of debt" /><published>2024-06-27T13:58:00-07:00</published><updated>2024-06-27T13:58:00-07:00</updated><id>http://localhost:4000/2024/06/27/secondary-forces-of-debt</id><content type="html" xml:base="http://localhost:4000/2024/06/27/secondary-forces-of-debt.html">&lt;p&gt;A general thing I hadn’t noticed about debts until lately:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Whenever Bob owes Alice, then Alice has reason to look after Bob, to the extent that increases the chance he satisfies the debt.&lt;/li&gt;
  &lt;li&gt;Yet at the same time, Bob has an incentive for Alice to disappear, insofar as it would relieve him.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These might be tiny incentives, and not overwhelm for instance Bob’s many reasons for not wanting Alice to disappear. &lt;!--ex--&gt;&lt;/p&gt;

&lt;p&gt;But the bigger the owing, the more relevant the incentives. When big enough, the former comes up as entities being “too big to fail”, and potentially rescued from destruction by those who would like them to repay or provide something expected of them in future. But the opposite must exist also: too big to succeed—where the abundance owed to you is so off-putting to provide that those responsible for it would rather disempower you. &lt;/p&gt;

&lt;p&gt;And if both kinds of incentive are around in whisps whenever there is a debt, surely they often get big enough to matter, even before they become the main game. &lt;/p&gt;

&lt;p&gt;For instance, if everyone around owes you a bit of money, I doubt anyone will murder you over it. But I wouldn’t be surprised if it motivated a bit more political disempowerment for you on the margin.&lt;/p&gt;

&lt;p&gt;There is a lot of owing that doesn’t arise from formal debt, where these things also apply. If we both agree that I—as your friend—am obliged to help you get to the airport, you may hope that I have energy and fuel and am in a good mood. Whereas I may (regretfully) be relieved when your flight is canceled.&lt;/p&gt;

&lt;p&gt;Money is an IOU from society for some stuff later, so having money is another kind of being owed. Perhaps this is part of the common resentment of wealth.&lt;/p&gt;

&lt;p&gt;I tentatively take this as reason to avoid debt in all its forms more: it’s not clear that the incentives of alliance in one direction make up for the trouble of the incentives for enmity in the other. And especially so when they are considered together—if you are going to become more aligned with someone, better it be someone who is not simultaneously becoming misaligned with you. Even if such incentives never change your behavior, every person you are obligated to help for an hour on their project is a person for whom you might feel a dash of relief if their project falls apart. And that is not fun to have sitting around in relationships. &lt;/p&gt;

&lt;p&gt;(Inpsired by reading The Debtor’s Revolt by Ben Hoffman lately, which may explicitly say this, but it’s hard to be sure because I didn’t follow it very well. Also perhaps inspired by a recent murder mystery spree, in which my intuitions have absorbed the heuristic that having something owed to you is a solid way to get murdered.)&lt;/p&gt;</content><author><name>Katja Grace</name></author><category term="meteuphoric" /><summary type="html">A general thing I hadn’t noticed about debts until lately: Whenever Bob owes Alice, then Alice has reason to look after Bob, to the extent that increases the chance he satisfies the debt. Yet at the same time, Bob has an incentive for Alice to disappear, insofar as it would relieve him. These might be tiny incentives, and not overwhelm for instance Bob’s many reasons for not wanting Alice to disappear. </summary></entry><entry><title type="html">Podcasts: AGI Show, Consistently Candid, London Futurists</title><link href="http://localhost:4000/2024/06/23/podcasts-agi-show-consistently-candid.html" rel="alternate" type="text/html" title="Podcasts: AGI Show, Consistently Candid, London Futurists" /><published>2024-06-23T06:34:00-07:00</published><updated>2024-06-23T06:34:00-07:00</updated><id>http://localhost:4000/2024/06/23/podcasts-agi-show-consistently-candid</id><content type="html" xml:base="http://localhost:4000/2024/06/23/podcasts-agi-show-consistently-candid.html">&lt;p&gt;For those of you who enjoy learning things via listening in on numerous slightly different conversations about them, and who also want to learn more about this&lt;a href=&quot;https://blog.aiimpacts.org/p/2023-ai-survey-of-2778-six-things&quot;&gt; AI survey&lt;/a&gt; I led, three more podcasts on the topic, and also other topics:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;The AGI Show&lt;/strong&gt;: &lt;a href=&quot;https://www.theagishow.com/2082819/15275026-ep-13-ai-researchers-expect-agi-sooner-w-katja-grace-co-founder-lead-researcher-ai-impacts&quot;&gt;audio&lt;/a&gt;, &lt;a href=&quot;https://www.youtube.com/watch?v=Nbpw90WQmgU&quot;&gt;video&lt;/a&gt; (other topics include: my own thoughts about the future of AI and my path into AI forecasting)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Consistently Candid&lt;/strong&gt;: &lt;a href=&quot;https://www.buzzsprout.com/2319950/15286236&quot;&gt;audio&lt;/a&gt; (other topics include: whether we should slow down AI progress, the best arguments for and against existential risk from AI, parsing the online AI safety debate)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;London Futurists&lt;/strong&gt;: &lt;a href=&quot;https://www.youtube.com/watch?v=xwJx_xqZI3Q&quot;&gt;audio&lt;/a&gt; (other topics include: are we in an arms race? Why is my blog called that?)&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Katja Grace</name></author><category term="ai" /><category term="meteuphoric" /><category term="podcasts" /><summary type="html">For those of you who enjoy learning things via listening in on numerous slightly different conversations about them, and who also want to learn more about this AI survey I led, three more podcasts on the topic, and also other topics: The AGI Show: audio, video (other topics include: my own thoughts about the future of AI and my path into AI forecasting) Consistently Candid: audio (other topics include: whether we should slow down AI progress, the best arguments for and against existential risk from AI, parsing the online AI safety debate) London Futurists: audio (other topics include: are we in an arms race? Why is my blog called that?)</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://substackcdn.com/image/fetch/w_1250,h_833,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_center/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd81a78e9-60a0-47ed-bde4-dc4a83b594c4_2378x1336.png" /><media:content medium="image" url="https://substackcdn.com/image/fetch/w_1250,h_833,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_center/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd81a78e9-60a0-47ed-bde4-dc4a83b594c4_2378x1336.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">What if a tech company forced you to move to NYC?</title><link href="http://localhost:4000/2024/06/08/what-if-tech-co-nyc.html" rel="alternate" type="text/html" title="What if a tech company forced you to move to NYC?" /><published>2024-06-08T23:18:00-07:00</published><updated>2024-06-08T23:18:00-07:00</updated><id>http://localhost:4000/2024/06/08/what-if-tech-co-nyc</id><content type="html" xml:base="http://localhost:4000/2024/06/08/what-if-tech-co-nyc.html">&lt;p&gt;It’s interesting to me how chill people sometimes are about the non-extinction future AI scenarios. Like, there seem to be opinions around along the lines of “pshaw, it might ruin your little sources of ‘meaning’, Luddite, but we have always had change and as long as the machines are pretty near the mark on rewiring your brain it will make everything amazing”. Yet I would bet that even that person, if faced instead with a policy that was going to forcibly relocate them to New York City, would be quite indignant, and want a lot of guarantees about the preservation of various very specific things they care about in life, and not be just like “oh sure, NYC has higher GDP/capita than my current city, sounds good”.&lt;!--ex--&gt;&lt;/p&gt;

&lt;p&gt;I read this as a lack of engaging with the situation as real. But possibly my sense that a non-negligible number of people have this flavor of position is wrong.&lt;/p&gt;</content><author><name>Katja Grace</name></author><category term="ai" /><category term="meteuphoric" /><summary type="html">It’s interesting to me how chill people sometimes are about the non-extinction future AI scenarios. Like, there seem to be opinions around along the lines of “pshaw, it might ruin your little sources of ‘meaning’, Luddite, but we have always had change and as long as the machines are pretty near the mark on rewiring your brain it will make everything amazing”. Yet I would bet that even that person, if faced instead with a policy that was going to forcibly relocate them to New York City, would be quite indignant, and want a lot of guarantees about the preservation of various very specific things they care about in life, and not be just like “oh sure, NYC has higher GDP/capita than my current city, sounds good”.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://substackcdn.com/image/fetch/w_1250,h_833,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_center/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F193cfc4c-5e3a-4f7d-908c-af0753f57951_4480x6586.jpeg" /><media:content medium="image" url="https://substackcdn.com/image/fetch/w_1250,h_833,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_center/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F193cfc4c-5e3a-4f7d-908c-af0753f57951_4480x6586.jpeg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Podcast: Center for AI Policy, on AI risk and listening to AI researchers</title><link href="http://localhost:4000/2024/06/05/caip-podcast.html" rel="alternate" type="text/html" title="Podcast: Center for AI Policy, on AI risk and listening to AI researchers" /><published>2024-06-05T20:00:00-07:00</published><updated>2024-06-05T20:00:00-07:00</updated><id>http://localhost:4000/2024/06/05/caip-podcast</id><content type="html" xml:base="http://localhost:4000/2024/06/05/caip-podcast.html">&lt;p&gt;I was on the &lt;a href=&quot;https://aipolicypod.substack.com/p/7-katja-grace-on-the-future-of-ai&quot;&gt;Center for AI Policy Podcast&lt;/a&gt;. We talked about topics around the &lt;a href=&quot;https://wiki.aiimpacts.org/ai_timelines/predictions_of_human-level_ai_timelines/ai_timeline_surveys/2023_expert_survey_on_progress_in_ai&quot;&gt;2023 Expert Survey on Progress in AI&lt;/a&gt;, including why I think AI is an existential risk, and how much to listen to AI researchers on the subject. Full transcript at the &lt;a href=&quot;https://aipolicypod.substack.com/p/7-katja-grace-on-the-future-of-ai&quot;&gt;link&lt;/a&gt;. 
&lt;!--ex--&gt;&lt;/p&gt;</content><author><name>Katja Grace</name></author><category term="podcast" /><category term="ai" /><category term="meteuphoric" /><summary type="html">I was on the Center for AI Policy Podcast. We talked about topics around the 2023 Expert Survey on Progress in AI, including why I think AI is an existential risk, and how much to listen to AI researchers on the subject. Full transcript at the link.</summary></entry><entry><title type="html">Is suffering like shit?</title><link href="http://localhost:4000/2024/05/30/is-suffering-like-shit.html" rel="alternate" type="text/html" title="Is suffering like shit?" /><published>2024-05-30T18:03:00-07:00</published><updated>2024-05-30T18:03:00-07:00</updated><id>http://localhost:4000/2024/05/30/is-suffering-like-shit</id><content type="html" xml:base="http://localhost:4000/2024/05/30/is-suffering-like-shit.html">&lt;p&gt;People seem to find suffering deep. Serious writings explore the experiences of all manner of misfortunes, and the nuances of trauma and torment involved. It’s hard to write an essay about a really good holiday that seems as profound as an essay about a really unjust abuse. A dark past can be plumbed for all manner of meaning, whereas a slew of happy years is boring and empty, unless perhaps they are &lt;em&gt;too&lt;/em&gt; happy and suggest something dark below the surface. (More thoughts in the vicinity of this &lt;a href=&quot;https://worldspiritsockpuppet.substack.com/p/home-up-and-down-colder-and-warmer-20-02-20&quot;&gt;here&lt;/a&gt;.)&lt;/p&gt;

&lt;p&gt;I wonder if one day suffering will be so avoidable that the myriad hurts of present-day existence will seem to future people like the problem of excrement getting on everything. Presumably a real issue in 1100 AD, but now irrelevant, unrelatable, decidedly not fascinating or in need of deep analysis.&lt;!--ex--&gt;&lt;/p&gt;</content><author><name>Katja Grace</name></author><category term="worldlypositions" /><summary type="html">People seem to find suffering deep. Serious writings explore the experiences of all manner of misfortunes, and the nuances of trauma and torment involved. It’s hard to write an essay about a really good holiday that seems as profound as an essay about a really unjust abuse. A dark past can be plumbed for all manner of meaning, whereas a slew of happy years is boring and empty, unless perhaps they are too happy and suggest something dark below the surface. (More thoughts in the vicinity of this here.) I wonder if one day suffering will be so avoidable that the myriad hurts of present-day existence will seem to future people like the problem of excrement getting on everything. Presumably a real issue in 1100 AD, but now irrelevant, unrelatable, decidedly not fascinating or in need of deep analysis.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://hosting.photobucket.com/images/i/katjasgrace/katjagrace_Excrement_in_the_gutters_of_a_street_in_a_European_c_4f3279b4-a13f-4d1b-be56-c2764d34ac36.pngScreen_Shot_2024-05-09_at_10.36.46_PM.png" /><media:content medium="image" url="https://hosting.photobucket.com/images/i/katjasgrace/katjagrace_Excrement_in_the_gutters_of_a_street_in_a_European_c_4f3279b4-a13f-4d1b-be56-c2764d34ac36.pngScreen_Shot_2024-05-09_at_10.36.46_PM.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Twin Peaks: under the air</title><link href="http://localhost:4000/2024/05/29/twin-peaks.html" rel="alternate" type="text/html" title="Twin Peaks: under the air" /><published>2024-05-29T23:00:00-07:00</published><updated>2024-05-29T23:00:00-07:00</updated><id>http://localhost:4000/2024/05/29/twin-peaks</id><content type="html" xml:base="http://localhost:4000/2024/05/29/twin-peaks.html">&lt;p&gt;&lt;em&gt;Content warning: low content&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;~ Feb 2021&lt;/p&gt;

&lt;p&gt;The other day I decided to try imbibing work-relevant blog posts via AI-generated recital, while scaling the Twin Peaks—large hills near my house in San Francisco, of the sort that one lives near and doesn’t get around to going to. It was pretty strange, all around.&lt;!--ex--&gt;&lt;/p&gt;

&lt;p&gt;For one thing, I was wearing sunglasses. I realize this is a thing people do all the time. Maybe it’s strange for them too, or maybe theirs aren’t orange. Mine were, which really changed the situation. For one thing, the glowing streetscapes felt unreal, like cheap science fiction. But also, all kinds of beauty seemed to want photographing, but couldn’t be seen with my camera. It was funny to realize that I’m surrounded by potential beauty all the time, that I would see if I had different eyes, or different glasses, or different sensory organs all together. Like, the potential for beauty is as real as the beauty I do see. (This is perhaps obvious, but something being obvious doesn’t mean you know it. And knowing something doesn’t mean you realize it. I’d say I knew it, but hadn’t realized it.)&lt;/p&gt;

&lt;p&gt;And then my ears were cornered in by these plugs spouting electronic declarations on the nature of coherent agents and such, which added to my sense of my head just not really being in the world, and instead being in a cozy little head cockpit, from which I could look out on the glowing alien landscape.&lt;/p&gt;

&lt;p&gt;My feet were also strange, but in the opposite direction. I recently got these new sock-shoes and I was trying them out for the first time. They are like well-fitting socks with strong but pliable rubber stuff sprayed on the bottom. Wearing them, you can feel the ground under your feet, as if you were bare-foot. Minus the sharp bits actually lacerating your feet, or the squishy bits sullying them. Walking along I imagined my freed feet were extra hands, holding the ground.&lt;/p&gt;

&lt;p&gt;I had only been up to Twin Peaks twice before, and I guess I had missed somehow exactly how crazy the view was. It was like standing on a giant breast, with a city-sea-bridge-forest-scape panoramaed around and under you over-realistically. The bridge disappeared into mystical mists and the supertankers swam epically on the vast blue expanse. I tried to photograph it multiple times but failed, partly because my camera couldn’t capture the warm orange tinge of the sea and the bridge rising from the burning mists, and partly for whatever reason that things sometimes look very different in photographs, and partly because I am always vaguely embarrassed photographing things with people looking at me, and there was a steady smattering of them.&lt;/p&gt;

&lt;p&gt;The roads had been blocked off to traffic during the pandemic. From a car I don’t realize what vast plateaus winding hillside roads are. For us pedestrians, these were like concert stages.&lt;/p&gt;

&lt;p&gt;The people I saw on my way up were either flying down the swooping roads on bikes and skateboards, in a fashion that made me involuntarily rehearse what I would do when they fell off, or flying unrealistically up the swooping roads on bikes, in a fashion that made me appreciate how good the best electric bikes must be now. I noticed as I watched one speed above me in awe that he flew the brand of his bourgeoisie bicycle on the back of his shirt, and wondered if he was just paid by them to ride up and down here all day, in the hope that someone would be so impressed that they would jot down the t-shirt label as the only clue to the rapidly disappearing bike’s identity, then google it later.&lt;/p&gt;

&lt;p&gt;I wandered atop the peaks, and confusingly collected a mob of crows flying above, apparently interested in me specifically. This was reasonably sinister, and in Australia birds can attack you, so I investigated on my phone, while walking hesitantly below the circling birds. At last they descended and alit on the road and guardrail around me, and stood looking at me.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f513e0f-03b1-4ca6-99cc-e44ee9ad1936_1200x1600.jpeg&quot; alt=&quot;View with ravens staring&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This picture captures the bizarreness of the situation about as badly as it captures the awesomeness of the scenery. It’s rare to be so much the center of a social situation with so little notion of what is expected of you or the meaning of it.&lt;/p&gt;

&lt;p&gt;I think things then just kind of dissipated and I made efficiently for home.&lt;/p&gt;</content><author><name>Katja Grace</name></author><category term="worldlypositions" /><category term="travel" /><summary type="html">Content warning: low content ~ Feb 2021 The other day I decided to try imbibing work-relevant blog posts via AI-generated recital, while scaling the Twin Peaks—large hills near my house in San Francisco, of the sort that one lives near and doesn’t get around to going to. It was pretty strange, all around.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f513e0f-03b1-4ca6-99cc-e44ee9ad1936_1200x1600.jpeg" /><media:content medium="image" url="https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f513e0f-03b1-4ca6-99cc-e44ee9ad1936_1200x1600.jpeg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">What is my Facebook feed about?</title><link href="http://localhost:4000/2024/05/15/what-is-my-facebook-feed-about.html" rel="alternate" type="text/html" title="What is my Facebook feed about?" /><published>2024-05-15T15:02:00-07:00</published><updated>2024-05-15T15:02:00-07:00</updated><id>http://localhost:4000/2024/05/15/what-is-my-facebook-feed-about</id><content type="html" xml:base="http://localhost:4000/2024/05/15/what-is-my-facebook-feed-about.html">&lt;p&gt;Sometimes I look at social media a bunch, but it would be hard for me to tell you what the actual content is, I suppose because whenever I’m looking at it, I’m focused on each object thing level in turn, not the big picture. So sometimes I’m curious what it is I read about there. Here is the answer for Facebook, in 2019—according to a list I found that appears to be a survey of such—and again now. Plausibly not at a useful level of abstraction, but I have a bit of a migraine and no more energy for this project.&lt;!--ex--&gt;&lt;/p&gt;

&lt;h2 id=&quot;november-11-2019&quot;&gt;&lt;em&gt;November 11 2019&lt;/em&gt;&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;Question about other people’s word usage&lt;/li&gt;
  &lt;li&gt;Question about other people’s inferences from word usage&lt;/li&gt;
  &lt;li&gt;Illustrated sex joke&lt;/li&gt;
  &lt;li&gt;Encouragement and instructions for opening up communication with attractive strangers in public places&lt;/li&gt;
  &lt;li&gt;Cute kid quote&lt;/li&gt;
  &lt;li&gt;Historic anti women’s suffrage leaflet&lt;/li&gt;
  &lt;li&gt;Cute kid quote and question about word usage&lt;/li&gt;
  &lt;li&gt;Recommendation and anecdote for Roam&lt;/li&gt;
  &lt;li&gt;Humorous anecdotal request for computer security problems&lt;/li&gt;
  &lt;li&gt;Joke I don’t get about Jesus with lots of emoticons&lt;/li&gt;
  &lt;li&gt;Sokal affair&lt;/li&gt;
  &lt;li&gt;Advice on surviving bushfires&lt;/li&gt;
  &lt;li&gt;Feminist writer screenshots and describes random online abuse from man&lt;/li&gt;
  &lt;li&gt;Sharing of personal health data&lt;/li&gt;
  &lt;li&gt;Science says a thing about dinosaurs and space&lt;/li&gt;
  &lt;li&gt;Tax policy trolling&lt;/li&gt;
  &lt;li&gt;Saudi spies at twitter news&lt;/li&gt;
  &lt;li&gt;Sexual/biological facts&lt;/li&gt;
  &lt;li&gt;Anecdote about medical system&lt;/li&gt;
  &lt;li&gt;Ethics injoke&lt;/li&gt;
  &lt;li&gt;Current reading list&lt;/li&gt;
  &lt;li&gt;Travel photos&lt;/li&gt;
  &lt;li&gt;Anecdote about australian bushfires with tenderness&lt;/li&gt;
  &lt;li&gt;Long letter about policy goings on within medical system&lt;/li&gt;
  &lt;li&gt;Request for acronym unknown to me&lt;/li&gt;
  &lt;li&gt;Funny law&lt;/li&gt;
  &lt;li&gt;Science about biology, cryonics&lt;/li&gt;
  &lt;li&gt;Question about word usage&lt;/li&gt;
  &lt;li&gt;Politics opinion on events&lt;/li&gt;
  &lt;li&gt;Futuristic anime style politics cartoon&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Notable patterns:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Questions about word usage: 4&lt;/p&gt;

&lt;p&gt;Kid related: 2&lt;/p&gt;

&lt;h2 id=&quot;may-15-2024&quot;&gt;&lt;em&gt;May 15, 2024&lt;/em&gt;&lt;/h2&gt;

&lt;p&gt;(Before checking, my sense is that the rate of posts about children and getting married is way up.)&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;AI company politics commentary&lt;/li&gt;
  &lt;li&gt;Job and city change&lt;/li&gt;
  &lt;li&gt;Invitation to help make game&lt;/li&gt;
  &lt;li&gt;Description of experience of making music&lt;/li&gt;
  &lt;li&gt;Book launch, project launch, new house&lt;/li&gt;
  &lt;li&gt;Cryptic fertility life update&lt;/li&gt;
  &lt;li&gt;Social commentary on language, gender and wokeness&lt;/li&gt;
  &lt;li&gt;Old photo of two famous men&lt;/li&gt;
  &lt;li&gt;Old photo of author winning an award&lt;/li&gt;
  &lt;li&gt;Event ad&lt;/li&gt;
  &lt;li&gt;Death of father&lt;/li&gt;
  &lt;li&gt;Photo of OP kissing&lt;/li&gt;
  &lt;li&gt;New job&lt;/li&gt;
  &lt;li&gt;Update on losing job&lt;/li&gt;
  &lt;li&gt;Wedding planning views&lt;/li&gt;
  &lt;li&gt;Book launch&lt;/li&gt;
  &lt;li&gt;Social commentary around political ideologies&lt;/li&gt;
  &lt;li&gt;Death of dog&lt;/li&gt;
  &lt;li&gt;Questioning claim about changes in breathing rate over history&lt;/li&gt;
  &lt;li&gt;Take on home buying&lt;/li&gt;
  &lt;li&gt;AI lab politics&lt;/li&gt;
  &lt;li&gt;Photo of partner on trip&lt;/li&gt;
  &lt;li&gt;Photo of self at work&lt;/li&gt;
  &lt;li&gt;Own photo of bird&lt;/li&gt;
  &lt;li&gt;Commentary on culture of judgment and author’s parents’ behavior&lt;/li&gt;
  &lt;li&gt;Remembering child relative who died&lt;/li&gt;
  &lt;li&gt;General self-help style commentary on human behavior&lt;/li&gt;
  &lt;li&gt;Photo of dogs&lt;/li&gt;
  &lt;li&gt;Mothers’ day and Aurora photos&lt;/li&gt;
  &lt;li&gt;Invitation to help make game&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Some notable patterns:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Kid related: 0-3 (maybe down from 2)&lt;/p&gt;

&lt;p&gt;Marriage related: 1&lt;/p&gt;

&lt;p&gt;—&amp;gt; I’m pretty wrong about the density of children and marriage related posts&lt;/p&gt;

&lt;p&gt;Job/book updates: 5 (up from 0)&lt;/p&gt;

&lt;p&gt;Smaller projects: 5 (up from 2-4)&lt;/p&gt;

&lt;p&gt;—&amp;gt; Actually a lot of project related posts&lt;/p&gt;

&lt;p&gt;Humor: ~0 (down from at least 5)&lt;/p&gt;

&lt;p&gt;Word usage: 1 (down from at least 4)&lt;/p&gt;

&lt;p&gt;—&amp;gt; Some classic sources of entertainment are way down (or we see random noise)&lt;/p&gt;</content><author><name>Katja Grace</name></author><category term="worldlypositions" /><summary type="html">Sometimes I look at social media a bunch, but it would be hard for me to tell you what the actual content is, I suppose because whenever I’m looking at it, I’m focused on each object thing level in turn, not the big picture. So sometimes I’m curious what it is I read about there. Here is the answer for Facebook, in 2019—according to a list I found that appears to be a survey of such—and again now. Plausibly not at a useful level of abstraction, but I have a bit of a migraine and no more energy for this project.</summary></entry></feed>