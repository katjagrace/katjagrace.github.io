<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-10-12T01:37:46-07:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">world spirit sock puppet</title><subtitle>Inclusive writings of Katja Grace</subtitle><author><name>Katja Grace</name></author><entry><title type="html">A game of mattering</title><link href="http://localhost:4000/2022/09/22/2022-game.html" rel="alternate" type="text/html" title="A game of mattering" /><published>2022-09-22T19:16:00-07:00</published><updated>2022-09-22T19:16:00-07:00</updated><id>http://localhost:4000/2022/09/22/2022-game</id><content type="html" xml:base="http://localhost:4000/2022/09/22/2022-game.html">&lt;p&gt;When I have an overwhelming number of things to do, and insufficient native urge to do them, I often arrange them into a kind of game for myself. The nature and appeal of this game has been relatively stable for about a year, after many years of evolution, so this seems like a reasonable time to share it. I also play it when I just want to structure my day and am in the mood for it. I currently play something like two or three times a week.&lt;/p&gt;

&lt;h1 id=&quot;the-game&quot;&gt;The game&lt;/h1&gt;

&lt;p&gt;The basic idea is to lay out the tasks in time a bit like obstacles in a platformer or steps in Dance Dance Revolution, then race through the obstacle course grabbing them under consistently high-but-doable time pressure.&lt;/p&gt;

&lt;p&gt;Here’s how to play:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Draw a grid with as many rows as there are remaining hours in your hoped for productive day, and ~3 columns. Each box stands for a particular ~20 minute period (I sometimes play with 15m or 30m periods.)&lt;/li&gt;
  &lt;li&gt;Lay out the gameboard: break the stuff you want to do into appropriate units, henceforth ‘items’. An item should fit comfortably in the length of a box, and it should be easy enough to verify completion. (This can be achieved through house rules such as ‘do x a tiny bit = do it until I have a sense that an appropriate tiny bit has been done’ as long as you are happy applying them). Space items out a decent amount so that the whole course is clearly feasible. Include everything you want to do in the day, including nice or relaxing things, or break activities. Drinks, snacks, tiny bouts of exercise, looking at news sites for 5 minutes, etc. Design the track thoughtfully, with hard bouts followed by relief before the next hard bout.&lt;/li&gt;
  &lt;li&gt;To play, start in the first box, then move through the boxes according to the time of day. The goal in playing is to collect as many items as you can, as you are forced along the track by the passage of time. You can collect an item by doing the task in or before you get to the box it is in. If it isn’t done by the end of the box, it gets left behind. However if you clear any box entirely, you get to move one item anywhere on the gameboard. So you can rescue something from the past, or rearrange the future to make it more feasible, or if everything is perfect, you can add an entirely new item somewhere.&lt;!--ex--&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I used to play this with tiny post-it stickers, which I would gather in a large moving pile, acting as a counter:&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;
&lt;img src=&quot;https://hosting.photobucket.com/images/i/katjasgrace/PXL_20210915_214726176.jpg&quot; alt=&quot;example of game with stickers&quot; width=&quot;300&quot; /&gt; &lt;img src=&quot;https://hosting.photobucket.com/images/i/katjasgrace/PXL_20210710_183723811.jpg&quot; alt=&quot;example of game with stickers&quot; width=&quot;300&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;Now I just draw the whole thing. Crossed out = collected; [] = rescued from the past, now implicitly in the final box; dot in the lower right = box cleared; dot next to item = task done but item stuck in the past (can be collected immediately if rescued).&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;
&lt;img src=&quot;https://hosting.photobucket.com/images/i/katjasgrace/IMG_0898.jpeg&quot; alt=&quot;IMG_0898&quot; width=&quot;500&quot; /&gt;
&lt;/p&gt;

&lt;h1 id=&quot;why-is-this-good&quot;&gt;Why is this good?&lt;/h1&gt;

&lt;p&gt;I think a basic problem with working on a big pile of things in a big expanse of time is that if you work or not during any particular minute, it feels like it makes nearly no difference to the expectation of success. I’m not quite sure why this is—in fact if I don’t work this minute, I’m going to get one minute less work done. But it feels like if I don’t work this minute, I only need to work a smidgen faster on average to get any particular amount of work done, so what does it matter if I work now or later? And if i had some particular goal (e.g. finishing writing some massive text today), it’s unlikely that my other efforts will get me exactly to the line where this minute pushed me over—probably I will either succeed with hours to spare (haha) or fail hours from my goals.&lt;/p&gt;

&lt;p&gt;I picture what’s going on as vaguely something like this—there is often some amount of work that is going to make your success likely, and if you know that you are on a locally steep part of the curve, it is more motivating than if you are either far away from the steep part or don’t know where you are:&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;
&lt;img src=&quot;https://hosting.photobucket.com/images/i/katjasgrace/IMG_0951.HEIC&quot; alt=&quot;IMG_0898&quot; width=&quot;500&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;Yet on the other hand, the appeal of various non-work activities this specific minute might be the most distinct and tangible things in the world. So when there is a lot to be done in a long time, not working often looks more exciting than working, even if a more rational accounting would disagree.&lt;/p&gt;

&lt;p&gt;Having a single specific thing to do within minutes is much more compelling: the task and the time are lined up so that my action right now matters. Slacking this minute is the difference between success and failure.&lt;/p&gt;

&lt;p&gt;It feels very different to have one email to deal with in three minutes and to have a thousand to deal with in next fifty hours.
&lt;!-- In the latter case, while in some sense the time pressure is the same, I probably start by getting myself a drink and pottering around staring out of the window or something. --&gt;&lt;/p&gt;

&lt;p&gt;One might naively respond to this issue by breaking up one’s tasks into tiny chunks, then laying them out in a day of tiny time boxes, then aiming for each to happen by the end of its allotment. But this will be terrible. A few boxes in, either you’ll be ahead or behind. And either way, your immediate actions have drifted away from feeling like they matter. If you are ahead, the pressure is off: you’ll probably succeed at the next increment whether or not you work hard now. If behind, you are definitely going to fail at doing the next box on time, and probably some others, and your present work is for an increased chance of catching up at some vague future box, much like before you had these boxes. (Plus your activities are no longer in line with what your plan was, which for me makes it tempting to scrap the whole thing and do something else.)
&lt;!-- and can substitute with all of the other intervening time. So again, working less hard this minute means you have to work a tiny bit harder in the next five boxes say, to catch up then. So what you do in this minute doesn&apos;t viscerally change the odds much. --&gt;&lt;/p&gt;

&lt;p&gt;A big innovation of this game is to instead ensure that you keep meeting tasks one at a time where each one matters in its moment, as in a game like Beat Saber or Dance Dance Revolution. The game achieves this by adjusting the slack to keep the next ten minutes’ action near the actually-mattering-to-success region all day. If you get behind you have to give up on items and move forward, so you aren’t left struggling for a low probability of catching up. If you get ahead, you add more items and thus tighten the slack.&lt;/p&gt;

&lt;p&gt;A thing I like about this is that it actually makes the activity more genuinely fun and compelling, and doesn’t involve trying to trick or uncomfortably binding oneself. It is superficially a lot like a ‘productivity hack’, but I associate these with somehow manipulating or forcing yourself to do something that you at some level have real reason to dislike. I expect such tricks to fail, and I don’t think I want them to succeed.&lt;/p&gt;

&lt;p&gt;This seems different: I think humans are just genuinely better at being in an enjoyable flow state when their activities have certain structures that are genuinely compatible with a variety of tasks. Beat saber wouldn’t be fun if all the boxes were just sitting in a giant pile and you had to beat your way through as many as you could over an hour. But with the boxes approaching one at a time, at a manageable rate, where what you do in each moment matters, it really is fun (for many people, I hear—I actually don’t love it, but I do appreciate this particular aspect). The same thing that makes Beat Saber more fun than Saber-a-bunch-of-boxes-on-your-own-schedule can genuinely also be applied to giant piles of tasks.&lt;/p&gt;

&lt;p&gt;The fact that this game has lasted a year in my life and I come back to it with verve points to it not being an enemy to any major part of myself.&lt;/p&gt;

&lt;p&gt;Another promising way of seeing this game is that this structure lets you see more clearly the true importance of each spent minute, when you were by default in error. Whereas for instance playing Civ IV for five minutes every time you do work (another sometimes way-of-being of mine) is less like causing yourself to perceive reality truly and more like trying to build an alternate incentive structure out of your mistaken perception, that adds up to rational behavior in the real world.&lt;/p&gt;

&lt;p&gt;If anyone else tries this, I’m curious to hear how it goes. My above explanation of its merit suggests it might be of broad value. But I also know that perhaps nobody in the world likes organizing things into little boxes as much as I do, so that could also be the main thing going on.&lt;/p&gt;</content><author><name>Katja Grace</name></author><category term="advice" /><category term="game" /><category term="meteuphoric" /><category term="worldlypositions" /><summary type="html">When I have an overwhelming number of things to do, and insufficient native urge to do them, I often arrange them into a kind of game for myself. The nature and appeal of this game has been relatively stable for about a year, after many years of evolution, so this seems like a reasonable time to share it. I also play it when I just want to structure my day and am in the mood for it. I currently play something like two or three times a week. The game The basic idea is to lay out the tasks in time a bit like obstacles in a platformer or steps in Dance Dance Revolution, then race through the obstacle course grabbing them under consistently high-but-doable time pressure. Here’s how to play: Draw a grid with as many rows as there are remaining hours in your hoped for productive day, and ~3 columns. Each box stands for a particular ~20 minute period (I sometimes play with 15m or 30m periods.) Lay out the gameboard: break the stuff you want to do into appropriate units, henceforth ‘items’. An item should fit comfortably in the length of a box, and it should be easy enough to verify completion. (This can be achieved through house rules such as ‘do x a tiny bit = do it until I have a sense that an appropriate tiny bit has been done’ as long as you are happy applying them). Space items out a decent amount so that the whole course is clearly feasible. Include everything you want to do in the day, including nice or relaxing things, or break activities. Drinks, snacks, tiny bouts of exercise, looking at news sites for 5 minutes, etc. Design the track thoughtfully, with hard bouts followed by relief before the next hard bout. To play, start in the first box, then move through the boxes according to the time of day. The goal in playing is to collect as many items as you can, as you are forced along the track by the passage of time. You can collect an item by doing the task in or before you get to the box it is in. If it isn’t done by the end of the box, it gets left behind. However if you clear any box entirely, you get to move one item anywhere on the gameboard. So you can rescue something from the past, or rearrange the future to make it more feasible, or if everything is perfect, you can add an entirely new item somewhere.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://hosting.photobucket.com/images/i/katjasgrace/PXL_20210915_214726176.jpg" /><media:content medium="image" url="https://hosting.photobucket.com/images/i/katjasgrace/PXL_20210915_214726176.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Calibration of a thousand predictions</title><link href="http://localhost:4000/2022/09/22/calibration.html" rel="alternate" type="text/html" title="Calibration of a thousand predictions" /><published>2022-09-22T01:30:00-07:00</published><updated>2022-09-22T01:30:00-07:00</updated><id>http://localhost:4000/2022/09/22/calibration</id><content type="html" xml:base="http://localhost:4000/2022/09/22/calibration.html">&lt;p&gt;I’ve been making predictions in a spreadsheet for the last four years, and I recently got to a thousand resolved predictions. Some observations:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;I’m surprisingly well calibrated for things that mostly aren’t my own behavior&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;. Here’s the calibration curve for 630 resolved predictions in that class:&lt;/p&gt;

    &lt;p style=&quot;text-align:center;&quot;&gt;&lt;img src=&quot;https://hosting.photobucket.com/images/i/katjasgrace/Calibration_for_no-special-context_forecasts_(mostly_excluding_much_own-behavior_prediction)(1).png&quot; alt=&quot;calibration no context predictions&quot; width=&quot;500&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;&lt;!--ex--&gt;&lt;/p&gt;

    &lt;p&gt;I don’t know what’s up with the 80% category, but the average miscalibration of the eleven categories is &amp;lt;3%.&lt;/p&gt;

    &lt;p&gt;At risk of bragging, this seems wild to me. My experience of making these predictions is fairly well described as ‘pulling a number out of thin air’&lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;. But apparently if you take all these conjured numbers, and look at the 45 of them that fell in the vicinity of 40%, then I implicitly guessed that 17.28 of those events would happen. And in fact 18 of them happened. WTF? Why wasn’t it eight of them or thirty-five of them? And that was only the fifth most accurate of the eleven buckets shown above! For predictions in the vicinity of 70%, I was off by 0.15%—I said 54.88 of those 80 things would happen, and in fact 55 of them happened.&lt;/p&gt;

    &lt;p&gt;Possibly people overall are just better calibrated than I thought. I had some remembered view that people’s asserted 90% confidence intervals were really 50% confidence intervals or something, but I can’t immediately find such evidence now, and I can find various graphs of &lt;a href=&quot;https://predictionbook.com/predictions&quot;&gt;groups&lt;/a&gt; of &lt;a href=&quot;https://www.researchgate.net/figure/Color-online-Calibration-Curves-Conditional-on-When-in-the-Questions-Life-the_fig1_320911494&quot;&gt;people&lt;/a&gt; &lt;a href=&quot;https://goodjudgment.com/wp-content/uploads/2021/10/Superforecasters-A-Decade-of-Stochastic-Dominance.pdf&quot;&gt;being&lt;/a&gt; on average fairly calibrated. And the &lt;a href=&quot;https://predictionbook.com/users/Baeboo&quot;&gt;handful&lt;/a&gt; &lt;a href=&quot;https://predictionbook.com/users/Tapetum-Lucidum&quot;&gt;of PredictionBook&lt;/a&gt; &lt;a href=&quot;https://predictionbook.com/users/gwern&quot;&gt;users&lt;/a&gt; &lt;a href=&quot;https://predictionbook.com/users/JoshuaZ&quot;&gt;I could&lt;/a&gt; &lt;a href=&quot;https://predictionbook.com/users/brunoparga&quot;&gt;find&lt;/a&gt; with more than a thousand predictions are not hugely worse.&lt;/p&gt;

    &lt;p&gt;If you are curious about what I predicted, I put examples at the end of this post.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;For the entire thousand predictions—the above plus 370 about my own behavior— I’m off by 6.25% on average (up from 2.95%) over the same eleven buckets.&lt;/p&gt;

    &lt;p style=&quot;text-align:center;&quot;&gt;&lt;img src=&quot;https://hosting.photobucket.com/images/i/katjasgrace/Calibration_for_all_predictions.png&quot; alt=&quot;calibration first 1000 resolved predictions&quot; width=&quot;500&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;As you may infer, I’m pretty bad overall at predicting my own behavior!&lt;/p&gt;

    &lt;p style=&quot;text-align:center;&quot;&gt;&lt;img src=&quot;https://hosting.photobucket.com/images/i/katjasgrace/Calibration_for_forecasts_with_context_(mostly_own-behavior)(1).png&quot; alt=&quot;calibration first 1000 resolved predictions&quot; width=&quot;500&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;This is more what I expected of a calibration curve—broadly overconfident. And perhaps its general worseness is explained by the appeal of optimism in predicting oneself. But it’s a pretty weird shape, which seems less explicable. If I think there’s a 40% chance that I’ll do something, apparently it’s not happening. If you want it to happen, you should hope I change my mind and put 5% on it!&lt;/p&gt;

    &lt;p&gt;I’m not sure what is up with this particular strange shape. But note that making predictions about one’s own behavior has particular complication, if one likes to be right. If you put a number below 50% on taking an action, then you have a disincentive to doing it. So you should then put a lower probability on it than you would have, which would make you even more wrong if you took the action, so you have a further disincentive to doing it, etc. I do generally look for a fixed point where given that I put probability &lt;em&gt;p&lt;/em&gt; on something (and the incentive consequences of that), I do think it will happen with probability &lt;em&gt;p&lt;/em&gt;. But this is a different process than the usual predicting process, and I could imagine it going wrong in strange ways. For instance, if I’m more motivated by being right than I thought, then 40% predictions which might have been 50% predictions originally should really be 5% predictinons. This theory doesn’t really work though, because then shouldn’t the lower categories also be especially overconfident? Whereas in fact they are okay.&lt;/p&gt;

    &lt;p&gt;(Maybe I just have free will? The kind of free will that manifests as being about 15% less likely to do anything than one might have expected seems disappointing, but the menu of possible free will options was never that inspiring.)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;example-predictions&quot;&gt;Example predictions&lt;/h2&gt;

&lt;p&gt;Here are some typical predictions, arbitrarily pulled from my spreadsheet and lightly edited:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;I will be invited to play ONUW today: 0.45 (true)&lt;/li&gt;
  &lt;li&gt;The trial bank transfers come through to my IBKR account by the end of Monday: 0.34 (false)&lt;/li&gt;
  &lt;li&gt;[Friend] will want to leave here for the day before I do: 0.05 (false)&lt;/li&gt;
  &lt;li&gt;[Friend] will seem notably sad in demeanor when I talk to [them]: 0.6 (false)&lt;/li&gt;
  &lt;li&gt;I will be paid by end Jan 27: 0.85 (true)&lt;/li&gt;
  &lt;li&gt;If I go inside shortly I see [friend]: 0.08 (false)&lt;/li&gt;
  &lt;li&gt;We have the [organization] party here: 0.55 (true)&lt;/li&gt;
  &lt;li&gt;I go to math party today: 0.88 (true)&lt;/li&gt;
  &lt;li&gt;I will get my period on Tuesday: 0.10 (true)&lt;/li&gt;
  &lt;li&gt;We will be invited to work at [office] for at least a week: 0.75 (false)&lt;/li&gt;
  &lt;li&gt;On Feb 5 we (including [friend], me, [friend]) are renting a new place: 0.73 (true)&lt;/li&gt;
  &lt;li&gt;We will run the arts and crafts room auction today (i.e. by midnight we will have as much info from the auction as we will get re which room is whos, ignoring processing of info we have): 0.40 (true)&lt;/li&gt;
  &lt;li&gt;[Person] is leading a new EAish org or CEO or COO of an existing EAish org by May 30 2023, where EAish includes orgs not culturally EA but doing things that are considered so by a decent fraction of EAs: 0.62 (TBD)&lt;/li&gt;
  &lt;li&gt;I will get to the office in time for lunch: 0.95 (true)&lt;/li&gt;
  &lt;li&gt;I see [housemate] tonight before midnight: 0.88 (true)&lt;/li&gt;
  &lt;li&gt;If I ask [attendee] ‘what did you think of [event I ran]?’, [they] will be strongly positive: 0.8 (false)&lt;/li&gt;
  &lt;li&gt;I see [friend]’s dad tonight before midnight: 0.95 (forgot to notice)&lt;/li&gt;
  &lt;li&gt;If I offer [person] a trial [they] will take it: 0.65 (true)&lt;/li&gt;
  &lt;li&gt;If I look at [friend]’s most recent Tweet, it is linking to [their] blog: 0.8 (false)&lt;/li&gt;
  &lt;li&gt;My weight is under [number] again before it is over [number] again: 0.75 (false)&lt;/li&gt;
  &lt;li&gt;I do all of my Complice goals tomorrow: 0.3 (false)&lt;/li&gt;
  &lt;li&gt;I will go to the office on Friday: 0.6 (true)&lt;/li&gt;
  &lt;li&gt;I will read the relevant chapter of Yuval book by the end of 2nd: 0.1 (false)&lt;/li&gt;
  &lt;li&gt;I weigh less than [weight] the first time I weigh myself tomorrow: 0.65 (true)&lt;/li&gt;
  &lt;li&gt;Lunch includes no kind of fish meat: 0.43 (true)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And some examples of own-behavior marked predictions:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Work goal as stated will be completed by end of day: start a document of feedback policies: 0.90 (true)&lt;/li&gt;
  &lt;li&gt;I ok [person]’s post before the meeting: 0.68 (false)&lt;/li&gt;
  &lt;li&gt;Work goal as stated, will be completed by Sunday 28th October: Respond to [person]: 0.80 (true)&lt;/li&gt;
  &lt;li&gt;Work goal as stated will be completed by midnight Sunday 30 September 2018: read [person]’s research: 0.4 (false)&lt;/li&gt;
  &lt;li&gt;Work goal as stated, will be completed by Sunday 4th November: Arrange to talk to [other researcher] about [employee] project […]: 0.3 (false)&lt;/li&gt;
  &lt;li&gt;Work goal as stated will be completed by midnight Sunday 30 September 2018: Think for 1h about [colleague] thing: 0.5 (true)&lt;/li&gt;
  &lt;li&gt;I have fewer than 1k emails in inbox at some point on Feb 10th: 0.87 (true)&lt;/li&gt;
  &lt;li&gt;I have written to [brother] by Feb 10th: 0.82 (true)&lt;/li&gt;
  &lt;li&gt;I will be home by 9pm: 0.97 (true)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Categories missing from these randomishly selected lists but notable in being particularly fun:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Predictions of history that I don’t know or remember, followed by looking it up on Wikipedia. A pretty fun combination of predicting things and reading Wikipedia.&lt;/li&gt;
  &lt;li&gt;Predictions of relationship persistence in successive episodes of &lt;em&gt;Married at First Sight&lt;/em&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;
—&lt;/p&gt;
&lt;h2 id=&quot;notes&quot;&gt;Notes&lt;/h2&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;I have a column where I write context on some predictions, which is usually that they are my own work goal, or otherwise a prediction about how I will behave. This graph excludes those, but keeps in some own-behavior prediction which I didn’t flag for whatever reason.) &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Except maybe more like art—do you know that feeling where you look at the sketch, and tilt your head from side to side, and say ‘no, a little bit more… just there….mmm…yes…’? It’s like that: ‘27%…no, a little more, 29%? No, 33%. 33%, yes.’ Except honestly it’s more ridiculous than that, because my brain often seems to have views about which particular digits should be involved. So it’s like, ‘23%…no, but mmm 3…33%, yes.’ I am generally in favor of question decomposition and outside views and all that, but to be clear, that’s not what I’m doing here. I might have been sometimes, but these are usually fast intuitive judgments. &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Katja Grace</name></author><category term="experiment" /><category term="prediction" /><summary type="html">I’ve been making predictions in a spreadsheet for the last four years, and I recently got to a thousand resolved predictions. Some observations: I’m surprisingly well calibrated for things that mostly aren’t my own behavior1. Here’s the calibration curve for 630 resolved predictions in that class: I have a column where I write context on some predictions, which is usually that they are my own work goal, or otherwise a prediction about how I will behave. This graph excludes those, but keeps in some own-behavior prediction which I didn’t flag for whatever reason.) &amp;#8617;</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://hosting.photobucket.com/images/i/katjasgrace/Calibration_for_no-special-context_forecasts_(mostly_excluding_much_own-behavior_prediction)(1).png" /><media:content medium="image" url="https://hosting.photobucket.com/images/i/katjasgrace/Calibration_for_no-special-context_forecasts_(mostly_excluding_much_own-behavior_prediction)(1).png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Update updates</title><link href="http://localhost:4000/2022/09/21/update-update.html" rel="alternate" type="text/html" title="Update updates" /><published>2022-09-21T22:14:00-07:00</published><updated>2022-09-21T22:14:00-07:00</updated><id>http://localhost:4000/2022/09/21/update-update</id><content type="html" xml:base="http://localhost:4000/2022/09/21/update-update.html">&lt;p&gt;You can now read or subscribe to this blog via &lt;a href=&quot;https://worldspiritsockpuppet.substack.com/&quot;&gt;world spirit sock stack&lt;/a&gt;, a Substack mirror of this site. I expect to see comments at &lt;a href=&quot;https://worldspiritsockpuppet.substack.com/&quot;&gt;wsss&lt;/a&gt; similarly often to &lt;a href=&quot;worldspiritsockpuppet.com/&quot;&gt;wssp&lt;/a&gt; (with both being more often than at various other places this crossposts, e.g. LessWrong).&lt;/p&gt;

&lt;p&gt;You can also be alerted to posts on Twitter via &lt;a href=&quot;https://twitter.com/wssockpuppet&quot;&gt;@wssockpuppet&lt;/a&gt;. I’m going to continue to Tweet about some subset of things on my &lt;a href=&quot;https://twitter.com/KatjaGrace&quot;&gt;personal account&lt;/a&gt;, so this runs a risk of double-seeing things.&lt;/p&gt;</content><author><name>Katja Grace</name></author><category term="logistics" /><summary type="html">You can now read or subscribe to this blog via world spirit sock stack, a Substack mirror of this site. I expect to see comments at wsss similarly often to wssp (with both being more often than at various other places this crossposts, e.g. LessWrong). You can also be alerted to posts on Twitter via @wssockpuppet. I’m going to continue to Tweet about some subset of things on my personal account, so this runs a risk of double-seeing things.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://hosting.photobucket.com/images/i/katjasgrace/Screen_Shot_2022-09-21_at_10.19.11_PM.png" /><media:content medium="image" url="https://hosting.photobucket.com/images/i/katjasgrace/Screen_Shot_2022-09-21_at_10.19.11_PM.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Podcasts on surveys, slower AI, AI arguments</title><link href="http://localhost:4000/2022/09/17/im-on-podcasts.html" rel="alternate" type="text/html" title="Podcasts on surveys, slower AI, AI arguments" /><published>2022-09-17T23:16:00-07:00</published><updated>2022-09-17T23:16:00-07:00</updated><id>http://localhost:4000/2022/09/17/im-on-podcasts</id><content type="html" xml:base="http://localhost:4000/2022/09/17/im-on-podcasts.html">&lt;p&gt;I recently talked to Michael Trazzi for his podcast, The Inside View. It just came out, so if that’s a conversation you want to sit in on, do so &lt;a href=&quot;https://www.youtube.com/watch?v=rSw3UVDZge0&quot;&gt;here&lt;/a&gt; [ETA: or read it &lt;a href=&quot;https://theinsideview.ai/katja&quot;&gt;here&lt;/a&gt;].&lt;/p&gt;

&lt;p&gt;The main topics were the &lt;a href=&quot;https://aiimpacts.org/what-do-ml-researchers-think-about-ai-in-2022/&quot;&gt;survey of ML folk&lt;/a&gt; I recently ran, and my thoughts on moving more slowly on potentially world-threatening AI research (which is to say, AI research in general, &lt;a href=&quot;https://aiimpacts.org/what-do-ml-researchers-think-about-ai-in-2022/&quot;&gt;according to&lt;/a&gt; the median surveyed ML researcher…). I also bet him a thousand dollars to his hundred that AI would not make blogging way more efficient in two years, if I recall. (I forget the exact terms, and there’s no way I’m listening to myself talk for that long to find out. If anyone else learns, I’m curious what I agreed to.)&lt;/p&gt;

&lt;p&gt;For completeness of podcast reporting: I forgot to mention that &lt;a href=&quot;https://axrp.net/episode/2021/07/23/episode-10-ais-future-and-dangers-katja-grace.html&quot;&gt;I also talked to Daniel Filan on AXRP&lt;/a&gt;, like a year ago. In other old news, I am opposed to the vibe of time-sensitivity often implicit in the public conversation.&lt;/p&gt;</content><author><name>Katja Grace</name></author><category term="ai" /><category term="xrisk" /><category term="podcast" /><category term="effectivealtruism" /><category term="meteuphoric" /><category term="worldlypositions" /><summary type="html">I recently talked to Michael Trazzi for his podcast, The Inside View. It just came out, so if that’s a conversation you want to sit in on, do so here [ETA: or read it here]. The main topics were the survey of ML folk I recently ran, and my thoughts on moving more slowly on potentially world-threatening AI research (which is to say, AI research in general, according to the median surveyed ML researcher…). I also bet him a thousand dollars to his hundred that AI would not make blogging way more efficient in two years, if I recall. (I forget the exact terms, and there’s no way I’m listening to myself talk for that long to find out. If anyone else learns, I’m curious what I agreed to.) For completeness of podcast reporting: I forgot to mention that I also talked to Daniel Filan on AXRP, like a year ago. In other old news, I am opposed to the vibe of time-sensitivity often implicit in the public conversation.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://hosting.photobucket.com/images/i/katjasgrace/Screen_Shot_2022-09-17_at_11.35.55_PM.png" /><media:content medium="image" url="https://hosting.photobucket.com/images/i/katjasgrace/Screen_Shot_2022-09-17_at_11.35.55_PM.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Survey advice</title><link href="http://localhost:4000/2022/08/23/survey-advice.html" rel="alternate" type="text/html" title="Survey advice" /><published>2022-08-23T19:54:00-07:00</published><updated>2022-08-23T19:54:00-07:00</updated><id>http://localhost:4000/2022/08/23/survey-advice</id><content type="html" xml:base="http://localhost:4000/2022/08/23/survey-advice.html">&lt;p&gt;Things I believe about making surveys, &lt;a href=&quot;https://aiimpacts.org/2016-expert-survey-on-progress-in-ai/&quot;&gt;after&lt;/a&gt; &lt;a href=&quot;https://aiimpacts.org/2022-expert-survey-on-progress-in-ai/&quot;&gt;making&lt;/a&gt; &lt;a href=&quot;https://worldspiritsockpuppet.com/2022/01/18/covid-survey.html&quot;&gt;some&lt;/a&gt; &lt;a href=&quot;https://worldspiritsockpuppet.com/2020/11/06/why-trump.html&quot;&gt;surveys&lt;/a&gt;:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;If you write a question that seems clear, there’s an unbelievably high chance that any given reader will misunderstand it. (Possibly this applies to things that aren’t survey questions also, but that’s a problem for another time.)&lt;/li&gt;
  &lt;li&gt;A better way to find out if your questions are clear is to repeatedly take a single individual person, and sit down with them, and ask them to take your survey while narrating the process: reading the questions aloud, telling you what they think the question is asking, explaining their thought process in answering it. If you do this repeatedly with different people until some are not confused at all, the questions are probably clear.&lt;/li&gt;
  &lt;li&gt;If you ask people very similar questions in different sounding ways, you can get very different answers (possibly related to the above, though that’s not obviously the main thing going on).&lt;!--ex--&gt;&lt;/li&gt;
  &lt;li&gt;One specific case of that: for some large class of events, if you ask people how many years until a 10%, 50%, 90% chance of event X occurring, you will get an earlier distribution of times than if you ask the probability that X will happen in 10, 20, 50 years. (I’ve only tried this with AI related things, but my guess is that it at least generalizes to other low-probability-seeming things. Also, if you just ask about 10% on its own, it is consistently different from 10% alongside 50% and 90%.&lt;/li&gt;
  &lt;li&gt;Given the complicated landscape of people’s beliefs about the world and proclivities to say certain things, there is a huge amount of scope for choosing questions to get answers that sound different to listeners (e.g. support a different side in a debate).&lt;/li&gt;
  &lt;li&gt;There is also scope for helping people think through a thing in a way that they would endorse, e.g. by asking a sequence of questions. This can also change what the answer sounds like, but seems ethical to me, whereas applications of 5 seem generally suss.&lt;/li&gt;
  &lt;li&gt;Often your respondent knows thing P and you want to know Q, and it is possible to infer something about Q from P. You then have a choice about which point in this inference chain to ask the person about. It seems helpful to notice this choice. For instance, if AI researchers know most about what AI research looks like, and you want to know whether human civilization will be imminently destroyed by renegade AI systems, you can ask about a) how fast AI progress appears to be progressing, b) when it will reach a certain performance bar, c) whether AI will cause something like human extinction. In the 2016 survey, we asked all of these.&lt;/li&gt;
  &lt;li&gt;Given the choice, if you are hoping to use the data as information, it is often good to ask people about things they know about. In 7, this points to aiming your question early in the reasoning chain, then doing the inference yourself.&lt;/li&gt;
  &lt;li&gt;Interest in surveys doesn’t seem very related to whether a survey is a good source of information on the topic surveyed on. One of the strongest findings of the 2016 survey IMO was that surveys like that are unlikely to be a reliable guide to the future.&lt;/li&gt;
  &lt;li&gt;This makes sense because surveys fulfill other purposes. Surveys are great if you want to know what people think about X, rather than what is true about X. Knowing what people think is often the important question. It can be good for legitimizing a view, or letting a group of people have common knowledge about what they think so they can start to act on it, including getting out of bad equilibria where everyone nominally supports claim P because they think others will judge them if not.&lt;/li&gt;
  &lt;li&gt;If you are surveying people with the intention of claiming a thing, it is helpful to think ahead about what you want to claim, and make sure you ask questions that will let you claim that, in a simple way. For instance, it is better to be able to say ‘80% of a random sample of shoppers at Tesco said that they like tomato more than beans’ than to say ‘80% of a sample of shoppers who were mostly at Tesco but also at Aldi (see footnote for complicated shopper selection process) say that they prefer tomato to peas, or (using a separate subset of shoppers) prefer peas to beans, from which we can infer that probably about 80% of shoppers in general, or more, prefer tomato to beans’. You want to be able to describe the setup and question in a way that is simple enough that the listener understands what happened, and see the significance of the finding.&lt;/li&gt;
  &lt;li&gt;If you are running a survey multiple times, and you want informative answers about whether there were differences in views between those times, you should probably run exactly the same survey and not change the questions even a tiny bit unless there is very strong reason to. This follows from 3.&lt;/li&gt;
  &lt;li&gt;Qualtrics costs thousands of dollars to use, and won’t let you sign up for an account or even know how much it might cost unless you book a meeting to talk to someone to sell it to you. &lt;a href=&quot;http://guidedtrack.com/&quot;&gt;Guidedtrack.com&lt;/a&gt; seems pretty nice, but I might not have been trying to do such complicated things there.&lt;/li&gt;
  &lt;li&gt;Running surveys seems underrated as an activity.&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Katja Grace</name></author><category term="survey" /><category term="advice" /><summary type="html">Things I believe about making surveys, after making some surveys: If you write a question that seems clear, there’s an unbelievably high chance that any given reader will misunderstand it. (Possibly this applies to things that aren’t survey questions also, but that’s a problem for another time.) A better way to find out if your questions are clear is to repeatedly take a single individual person, and sit down with them, and ask them to take your survey while narrating the process: reading the questions aloud, telling you what they think the question is asking, explaining their thought process in answering it. If you do this repeatedly with different people until some are not confused at all, the questions are probably clear. If you ask people very similar questions in different sounding ways, you can get very different answers (possibly related to the above, though that’s not obviously the main thing going on).</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://hosting.photobucket.com/images/i/katjasgrace/mic-narra-RA3f0b26qwE-unsplash.jpg" /><media:content medium="image" url="https://hosting.photobucket.com/images/i/katjasgrace/mic-narra-RA3f0b26qwE-unsplash.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">What do ML researchers think about AI in 2022?</title><link href="http://localhost:4000/2022/08/04/ai_2022_survey.html" rel="alternate" type="text/html" title="What do ML researchers think about AI in 2022?" /><published>2022-08-04T10:30:00-07:00</published><updated>2022-08-04T10:30:00-07:00</updated><id>http://localhost:4000/2022/08/04/ai_2022_survey</id><content type="html" xml:base="http://localhost:4000/2022/08/04/ai_2022_survey.html">&lt;p&gt;&lt;em&gt;Crossposted from &lt;a href=&quot;https://aiimpacts.org/what-do-ml-researchers-think-about-ai-in-2022/&quot;&gt;AI Impacts&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;AI Impacts just finished collecting data from a new survey of ML researchers, as similar to the &lt;a href=&quot;https://aiimpacts.org/2016-expert-survey-on-progress-in-ai/&quot; data-type=&quot;post&quot; data-id=&quot;753&quot;&gt;2016 one&lt;/a&gt; as practical, aside from a couple of new questions that seemed too interesting not to add.&lt;!--ex--&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://aiimpacts.org/2022-expert-survey-on-progress-in-ai/&quot; data-type=&quot;post&quot; data-id=&quot;3246&quot;&gt;This page&lt;/a&gt; reports on it preliminarily, and we’ll be adding more details there. But so far, some things that might interest you:&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;&lt;strong&gt;37 years until a 50% chance of &lt;a href=&quot;https://aiimpacts.org/2022-expert-survey-on-progress-in-ai/#Definitions&quot;&gt;HLMI&lt;/a&gt; &lt;/strong&gt;according to a complicated aggregate forecast (and biasedly not including data from questions about the conceptually similar Full Automation of Labor, which in 2016 prompted strikingly later estimates)&lt;strong&gt;.&lt;/strong&gt; This 2059 aggregate HLMI timeline has become about eight years shorter in the six years since 2016, when the aggregate prediction was 2061, or 45 years out. Note that all of these estimates are conditional on &amp;#8220;human scientific activity continu[ing] without major negative disruption.&amp;#8221;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;P(extremely bad outcome)=5%&lt;/strong&gt; The median respondent believes the probability that the long-run effect of advanced AI on humanity will be &amp;#8220;extremely bad (e.g., human extinction)&amp;#8221; is 5%. This is the same as it was in 2016 (though Zhang et al 2022 found 2% in a similar but non-identical question). Many respondents put the chance substantially higher: 48% of respondents gave at least 10% chance of an extremely bad outcome. Though another 25% put it at 0%.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Explicit P(doom)=5-10% &lt;/strong&gt;The levels of badness involved in that last question seemed ambiguous in retrospect, so I added two new questions about human extinction explicitly. The median respondent&amp;#8217;s probability of x-risk from humans failing to control AI&lt;span id=&quot;easy-footnote-1-3250&quot; class=&quot;easy-footnote-margin-adjust&quot;&gt;&lt;/span&gt;&lt;span class=&quot;easy-footnote&quot;&gt;&lt;a href=&quot;#easy-footnote-bottom-1-3250&quot; title=&quot;Or, &amp;amp;#8216;human inability to control future advanced AI systems causing human extinction or similarly permanent and severe disempowerment of the human species&amp;amp;#8217;&quot;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/span&gt; was 10%, weirdly more than median chance of human extinction from AI in general&lt;span id=&quot;easy-footnote-2-3250&quot; class=&quot;easy-footnote-margin-adjust&quot;&gt;&lt;/span&gt;&lt;span class=&quot;easy-footnote&quot;&gt;&lt;a href=&quot;#easy-footnote-bottom-2-3250&quot; title=&quot;That is, &amp;amp;#8216;future AI advances causing human extinction or similarly permanent and severe disempowerment of the human species&amp;amp;#8217;&quot;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/span&gt;, at 5%. This might just be because different people got these questions and the median is quite near the divide between 5% and 10%. The most interesting thing here is probably that these are both very high—it seems the &amp;#8216;extremely bad outcome&amp;#8217; numbers in the old question were not just catastrophizing merely disastrous AI outcomes. &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Support for AI safety research is up&lt;/strong&gt;: 69% of respondents believe society should prioritize AI safety research &amp;#8220;more&amp;#8221; or &amp;#8220;much more&amp;#8221; than it is currently prioritized, up from 49% in 2016. &lt;/li&gt;&lt;li&gt;&lt;strong&gt;The median respondent thinks there is an &amp;#8220;about even chance&amp;#8221; that an argument given for an intelligence explosion is broadly correct.&lt;/strong&gt; The median respondent also believes machine intelligence will probably (60%) be &amp;#8220;vastly better than humans at all professions&amp;#8221; within 30 years of HLMI, and that the rate of global technological improvement will probably (80%) dramatically increase (e.g., by a factor of ten) as a result of machine intelligence within 30 years of HLMI.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Years/probabilities framing effect persists: &lt;/strong&gt;if you ask people for probabilities of things occurring in a fixed number of years, you get later estimates than if you ask for the number of years until a fixed probability will obtain. This looked very robust in 2016, and shows up again in the 2022 HLMI data. Looking at just the people we asked for years, the aggregate forecast is 29 years, whereas it is 46 years for those asked for probabilities. (We haven&amp;#8217;t checked in other data or for the bigger framing effect yet.)&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Predictions vary a lot&lt;/strong&gt;. Pictured below: the attempted reconstructions of people&amp;#8217;s probabilities of HLMI over time, which feed into the aggregate number above. There are few times and probabilities that someone doesn&amp;#8217;t basically endorse the combination of.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;You can download the data&lt;/strong&gt; &lt;a href=&quot;https://docs.google.com/spreadsheets/d/1u_qcG6erXkH4EJgygl2fpkpJENAv6-kFWJejsw1oA1Q/edit?usp=sharing&quot;&gt;here&lt;/a&gt; (slightly cleaned and anonymized) and do your own analysis. (If you do, I encourage you to share it!)&lt;/li&gt;&lt;/ul&gt;

&lt;div class=&quot;center&quot;&gt;
  &lt;p&gt;&lt;img src=&quot;http://aiimpacts.org/wp-content/uploads/2022/08/Screen-Shot-2022-08-04-at-02.55.28.jpg&quot; alt=&quot;Individual inferred gamma distributions&quot; /&gt;&lt;/p&gt;

  &lt;p&gt;Individual inferred gamma distributions&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;The survey had a lot of questions (randomized between participants to make it a reasonable length for any given person), so this blog post doesn’t cover much of it. A bit more is on &lt;a href=&quot;https://aiimpacts.org/2022-expert-survey-on-progress-in-ai/&quot; data-type=&quot;post&quot; data-id=&quot;3246&quot;&gt;the page&lt;/a&gt; and more will be added. &lt;/p&gt;

&lt;p&gt;Thanks to many people for help and support with this project! (Many but probably not all listed on the survey page.)&lt;/p&gt;

&lt;hr class=&quot;wp-block-separator has-text-color has-background has-cyan-bluish-gray-background-color has-cyan-bluish-gray-color is-style-wide&quot; /&gt;

&lt;p&gt;&lt;em&gt;Cover image: Probably a bootstrap confidence interval around an aggregate of the above forest of inferred gamma distributions, but honestly everyone who can be sure about that sort of thing went to bed a while ago. So, one for a future update. I have more confidently held views on whether one should let uncertainty be the enemy of putting things up.&lt;/em&gt;&lt;/p&gt;

&lt;hr class=&quot;wp-block-separator has-text-color has-background has-cyan-bluish-gray-background-color has-cyan-bluish-gray-color is-style-wide&quot; /&gt;

&lt;ol class=&quot;easy-footnotes-wrapper&quot;&gt;&lt;li class=&quot;easy-footnote-single&quot;&gt;&lt;span id=&quot;easy-footnote-bottom-1-3250&quot; class=&quot;easy-footnote-margin-adjust&quot;&gt;&lt;/span&gt;Or, &amp;#8216;human inability to control future advanced AI systems causing human extinction or similarly permanent and severe disempowerment of the human species&amp;#8217;&lt;a class=&quot;easy-footnote-to-top&quot; href=&quot;#easy-footnote-1-3250&quot;&gt;&lt;/a&gt;&lt;/li&gt;&lt;li class=&quot;easy-footnote-single&quot;&gt;&lt;span id=&quot;easy-footnote-bottom-2-3250&quot; class=&quot;easy-footnote-margin-adjust&quot;&gt;&lt;/span&gt;That is, &amp;#8216;future AI advances causing human extinction or similarly permanent and severe disempowerment of the human species&amp;#8217;&lt;a class=&quot;easy-footnote-to-top&quot; href=&quot;#easy-footnote-2-3250&quot;&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;/div&amp;gt;&amp;lt;div id=&quot;custom_html-19&quot; class=&quot;widget_text mh-widget mh-posts-2 widget_custom_html&quot;&amp;gt;&amp;lt;div class=&quot;textwidget custom-html-widget&quot;&amp;gt;&amp;lt;div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>Katja Grace</name></author><category term="meteuphoric" /><category term="ai" /><category term="effectivealtruism" /><summary type="html">Crossposted from AI Impacts AI Impacts just finished collecting data from a new survey of ML researchers, as similar to the 2016 one as practical, aside from a couple of new questions that seemed too interesting not to add.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://hosting.photobucket.com/images/i/katjasgrace/Screen_Shot_2022-08-04_at_02.53.13.png" /><media:content medium="image" url="https://hosting.photobucket.com/images/i/katjasgrace/Screen_Shot_2022-08-04_at_02.53.13.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Book review: The Passenger by Lisa Lutz</title><link href="http://localhost:4000/2022/06/23/book-review-the-passenger.html" rel="alternate" type="text/html" title="Book review: The Passenger by Lisa Lutz" /><published>2022-06-23T15:57:00-07:00</published><updated>2022-06-23T15:57:00-07:00</updated><id>http://localhost:4000/2022/06/23/book-review-the-passenger</id><content type="html" xml:base="http://localhost:4000/2022/06/23/book-review-the-passenger.html">&lt;p&gt;
&lt;span class=&quot;aside&quot;&gt;Spoiler warning: spoilers for The Passenger by Lisa Lutz, and In the Cart, by Anton Chekhov.
&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;
I took up &lt;a href=&quot;https://www.goodreads.com/book/show/26154406-the-passenger&quot;&gt;this book&lt;/a&gt; looking for a page-turner. It was, but hours before the end I thought its main contribution to my mental life would be the visceral knowledge that page-turners can be undelicious. It felt cold, and getting into its world felt bad. The protagonist slunk around dark and uncomfortable places, killing people, scheming harshly, perceiving low beams as dangers to the heads of tall men, and that sort of thing. With some amount of fretting about what she was becoming. I wanted to turn the pages, but I also kind of wanted it to end, and for me to read something more squarely enjoyable next time.
&lt;/p&gt;
&lt;!--ex--&gt;
&lt;p&gt;
Then the end was different, and kept coming back to me in the day, and turned the rest around and gave it new meaning. Like the image of a long dark tunnel becomes something different if you step away and see that it starts in the loveliest of fields. After a long dark tunnel of a book, we turn around and see where the heroine came from, and her teenage innocence and goodness newly fills out the potentially empty person we have been watching. And her past isn’t really discordant—I think I just wrote her off fast. This endless night began in that day, and seeing so makes the full picture both warm and intense, where it had seemed like cheap suspense and violence.
&lt;/p&gt;
&lt;p&gt;
In that abstract description, I suppose it is a bit like ‘In The Cart’ by Chekhov: we watch a dreary life, then at last that life is pulled into a perspective where we see its warm and hopeful start, unreachably distant. And it changes the flavor.
&lt;/p&gt;
&lt;p&gt;
I have not much idea if what I saw was what Lisa Lutz was going for, but if she was, and if other readers are like me (haha) then I think having 85% of the book be unpleasant was probably called for.
&lt;/p&gt;</content><author><name>Katja Grace</name></author><category term="book" /><category term="review" /><summary type="html">Spoiler warning: spoilers for The Passenger by Lisa Lutz, and In the Cart, by Anton Chekhov. I took up this book looking for a page-turner. It was, but hours before the end I thought its main contribution to my mental life would be the visceral knowledge that page-turners can be undelicious. It felt cold, and getting into its world felt bad. The protagonist slunk around dark and uncomfortable places, killing people, scheming harshly, perceiving low beams as dangers to the heads of tall men, and that sort of thing. With some amount of fretting about what she was becoming. I wanted to turn the pages, but I also kind of wanted it to end, and for me to read something more squarely enjoyable next time.</summary></entry><entry><title type="html">An inquiry into the thoughts of twenty-five people in India</title><link href="http://localhost:4000/2022/05/28/inquiry-twenty-five-people-in-india.html" rel="alternate" type="text/html" title="An inquiry into the thoughts of twenty-five people in India" /><published>2022-05-28T01:13:00-07:00</published><updated>2022-05-28T01:13:00-07:00</updated><id>http://localhost:4000/2022/05/28/inquiry-twenty-five-people-in-india</id><content type="html" xml:base="http://localhost:4000/2022/05/28/inquiry-twenty-five-people-in-india.html">&lt;p&gt;Sometimes I get excited about running surveys. &lt;a href=&quot;https://docs.google.com/spreadsheets/d/1UzZf_1j7BmaacE60Sl6YbSdMMldWr8REVTXJDIVKkws/edit?usp=sharing&quot;&gt;Here&lt;/a&gt; is a &lt;a href=&quot;https://app.positly.com/&quot;&gt;Positly&lt;/a&gt; one from November 2020 in which I asked the following questions, to participants from India:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;What are you looking forward to this week?&lt;/li&gt;
  &lt;li&gt;What do you think of as the most important thing going on in the world right now?&lt;/li&gt;
  &lt;li&gt;If you had a spare half hour right now, what would you do with it?&lt;/li&gt;
  &lt;li&gt;What is something you changed your mind about recently?&lt;/li&gt;
  &lt;li&gt;What in life is more important than other people realize?&lt;/li&gt;
  &lt;li&gt;If someone gave you $5 right now, what would you do with it?&lt;/li&gt;
  &lt;li&gt;Who is someone you think of as a hero?&lt;/li&gt;
  &lt;li&gt;Are you paying attention to the US election?&lt;/li&gt;
  &lt;li&gt;What was the biggest news story this year?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;br /&gt;
I don’t recall any notable constraints other than the location requirement, but I barely remember doing this.&lt;/p&gt;</content><author><name>Katja Grace</name></author><category term="survey" /><summary type="html">Sometimes I get excited about running surveys. Here is a Positly one from November 2020 in which I asked the following questions, to participants from India: What are you looking forward to this week? What do you think of as the most important thing going on in the world right now? If you had a spare half hour right now, what would you do with it? What is something you changed your mind about recently? What in life is more important than other people realize? If someone gave you $5 right now, what would you do with it? Who is someone you think of as a hero? Are you paying attention to the US election? What was the biggest news story this year? I don’t recall any notable constraints other than the location requirement, but I barely remember doing this.</summary></entry><entry><title type="html">Podcast: with Spencer Greenberg on groupstruckness and boundedness</title><link href="http://localhost:4000/2022/05/19/podcast-clearer-thinking-groupstruck.html" rel="alternate" type="text/html" title="Podcast: with Spencer Greenberg on groupstruckness and boundedness" /><published>2022-05-19T20:57:00-07:00</published><updated>2022-05-19T20:57:00-07:00</updated><id>http://localhost:4000/2022/05/19/podcast-clearer-thinking-groupstruck</id><content type="html" xml:base="http://localhost:4000/2022/05/19/podcast-clearer-thinking-groupstruck.html">&lt;p&gt;I &lt;a href=&quot;https://clearerthinkingpodcast.com/episode/105&quot;&gt;talked to Spencer Greenberg&lt;/a&gt; a little while ago for his podcast &lt;a href=&quot;https://clearerthinkingpodcast.com/&quot;&gt;Clearer Thinking&lt;/a&gt;. The recording is out today. According to his website we discussed:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;What does it mean to be “groupstruck”? How does groupstruck-ness differ from the bystander effect, normalcy bias, and other related cognitive biases? How do we break people out of being groupstruck? What does it mean to be a “bounded” person? How can we build up better decision-making heuristics? What sorts of decisions do people usually not quantify but should (and vice versa)? How can we make rational relationship decisions without coming across as “calculating” or cold? How does anthropic reasoning affect our hypotheses about the nature of the universe and life within it (i.e., the Fermi paradox, the simulation hypothesis, etc.)?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;You can listen or read the transcript &lt;a href=&quot;https://clearerthinkingpodcast.com/episode/105&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;</content><author><name>Katja Grace</name></author><category term="podcast" /><category term="sociology" /><category term="psychology" /><category term="decisionmaking" /><category term="anthropics" /><summary type="html">I talked to Spencer Greenberg a little while ago for his podcast Clearer Thinking. The recording is out today. According to his website we discussed: What does it mean to be “groupstruck”? How does groupstruck-ness differ from the bystander effect, normalcy bias, and other related cognitive biases? How do we break people out of being groupstruck? What does it mean to be a “bounded” person? How can we build up better decision-making heuristics? What sorts of decisions do people usually not quantify but should (and vice versa)? How can we make rational relationship decisions without coming across as “calculating” or cold? How does anthropic reasoning affect our hypotheses about the nature of the universe and life within it (i.e., the Fermi paradox, the simulation hypothesis, etc.)? You can listen or read the transcript here.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://hosting.photobucket.com/images/i/katjasgrace/markus-winkler-afW1hht0NSs-unsplash.jpg" /><media:content medium="image" url="https://hosting.photobucket.com/images/i/katjasgrace/markus-winkler-afW1hht0NSs-unsplash.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Proposal: Twitter dislike button</title><link href="http://localhost:4000/2022/05/17/twitter-dislike-button.html" rel="alternate" type="text/html" title="Proposal: Twitter dislike button" /><published>2022-05-17T12:21:00-07:00</published><updated>2022-05-17T12:21:00-07:00</updated><id>http://localhost:4000/2022/05/17/twitter-dislike-button</id><content type="html" xml:base="http://localhost:4000/2022/05/17/twitter-dislike-button.html">&lt;p&gt;The popular story of Twitter’s role in the ruin of civilization is that it is a runaway trash fire of reciprocal anger and offense, where otherwise nice people are possessed by overwhelming outrages, and drawn into throwing their own energy behind creating the vilest and most vindictive responses to what they see, turning away from reason and hurting others in turn, and so the place continues.&lt;!--ex--&gt;&lt;/p&gt;

&lt;p&gt;I’m not sure how much of Twitter activity this accounts for (apparently &lt;a href=&quot;https://twitter.com/michael_nielsen/status/975884635535101952&quot;&gt;Michael Nielsen enjoys an entirely different place&lt;/a&gt;, and my experience seems pretty nice too). But I think there’s a real pattern of this kind, which makes game theoretic sense, and goes something like this:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;People say things&lt;/li&gt;
  &lt;li&gt;People read these things&lt;/li&gt;
  &lt;li&gt;If anything seems objectionable to any of these people, then they repost those things with commentary, and everyone else reads them extra.&lt;/li&gt;
  &lt;li&gt;In the next round, people (or the ones who who get attention) say objectionable things (that they expect will get attention), about objectionable things (that they have their attention on from the last round)&lt;/li&gt;
  &lt;li&gt;etc.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;To lay out the effects of all this more clearly:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;People disproportionately read things they don’t like, which is presumably bad for them&lt;/li&gt;
  &lt;li&gt;People get the visceral sense that others are disproportionately writing things they don’t like, which is misleading, and not in a helpful-for-public-friendship way&lt;/li&gt;
  &lt;li&gt;Things people don’t like get extra space in the public conversation&lt;/li&gt;
  &lt;li&gt;People who tend to write things that others don’t like get extra power and attention instead of less&lt;/li&gt;
  &lt;li&gt;Writing things other people don’t like is incentivized (if you want attention, writing things other people don’t like is probably somewhat better than writing things people do like, and way better than writing things they don’t feel strongly about).&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Supposing something like this model is true, and bad, it seems to me that there is a really simple solution: &lt;strong&gt;add a dislike button.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;That is, what if when a person sees a thing they don’t like, instead of broadcasting it to others, they register their disapproval by quietly clicking a different button next to the heart, and then Twitter shows it to other people less instead of more? You can still retweet it if you especially want other people to see it more, but adding attention wouldn’t be the default disapproval vote.&lt;/p&gt;

&lt;p&gt;This is not an original idea, and the other major websites that do it have not, to my knowledge, been run out of business by a dearth of disagreement. I think they are also not so much known for the above dynamic.&lt;/p&gt;

&lt;p&gt;I posit that a Twitter downvote button would be great. What am I missing?&lt;/p&gt;</content><author><name>Katja Grace</name></author><category term="advice" /><category term="institutiondesign" /><category term="twitter" /><summary type="html">The popular story of Twitter’s role in the ruin of civilization is that it is a runaway trash fire of reciprocal anger and offense, where otherwise nice people are possessed by overwhelming outrages, and drawn into throwing their own energy behind creating the vilest and most vindictive responses to what they see, turning away from reason and hurting others in turn, and so the place continues.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://hosting.photobucket.com/images/i/katjasgrace/downvote2.png" /><media:content medium="image" url="https://hosting.photobucket.com/images/i/katjasgrace/downvote2.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>